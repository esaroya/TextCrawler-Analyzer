1|"DiscussionWeekly Entering & Transitioning Thread | 31 May 2020 - 07 Jun 2020 (self.datascience)"|datascience-bot|67|6|"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

Learning resources (e.g. books, tutorials, videos)
Traditional education (e.g. schools, degrees, electives)
Alternative education (e.g. online courses, bootcamps)
Job search questions (e.g. resumes, applying, career prospects)
Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the FAQ and [Resources](Resources) pages on our wiki. You can also search for answers in past weekly threads.
"|welcom week 's enter & transit thread ! thi thread question get start , studi , transit data scienc field . topic includ : learn resourc ( e.g . book , tutori , video ) tradit educ ( e.g . school , degre , elect ) altern educ ( e.g . onlin cours , bootcamp ) job search question ( e.g . resum , appli , career prospect ) elementari question ( e.g . start , next ) while wait answer commun , check faq [ resourc ] ( resourc ) page wiki . you also search answer past weekli thread .
2|Job SearchMy thoughts on the data science job hunt during COVID-19 (self.datascience)|SpicyElephant|99|257|"Some background: I have 6 years of DS experience, 2 masters degrees, and spent a few years as a data analyst as well. Laid off from a smaller company in the midwest due to COVID-19 cutbacks.
​

""Data scientist"" is turning into a blanket term. So is ""data analyst"". So many of the jobs I've looked at truly want a data engineer/DBA but ask for a data scientist. Or want a data scientist but ask for an entry level data analyst. Expand your search terms, but read the job description to figure out what the company really wants. This changes every time I'm on the job market even in my short tenure as a data scientist. When did ""Machine Learning Engineer"" become so big??
On that note: ""Senior"" vs ""Lead"" vs ""Entry Level""...the difference to me is huge, but most companies seem to be pretty flexible with what they're posting. Some entry level jobs have been open to changing to senior level, some lead/manager level would be fine with senior. If you like a job but are weary about the experience required, just ask the hiring manager/recruiter that posted it.
Every company has a different way of testing your knowledge. So far I've taken a data science timed assessment (no outside resources), completed a take-home assessment (48 hours and a dataset), and presented a past project for 30 minutes, all for different companies. Be prepared for just about anything, but use how they test you as a clue into their culture. For me, I love the take-home tests and presentations because they give me a chance to show what I know without as much of the pressure.
Companies are starting to open back up. Many job postings were taken down from March-May, but as of today the number of openings is expanding rapidly. Region may be a big factor. The companies I have interviewed with have stuck to either all virtual, or majority virtual with one in-person interview with masks and social distancing.

​
Best of luck to everyone in their job search!
"|some background : I 6 year DS experi , 2 master degre , spent year data analyst well . laid smaller compani midwest due covid-19 cutback . ​ '' data scientist '' turn blanket term . So `` data analyst '' . So mani job I 've look truli want data engineer/dba ask data scientist . Or want data scientist ask entri level data analyst . expand search term , read job descript figur compani realli want . thi chang everi time I 'm job market even short tenur data scientist . when `` machin learn engin '' becom big ? ? On note : `` senior '' vs `` lead '' vs `` entri level '' ... differ huge , compani seem pretti flexibl 're post . some entri level job open chang senior level , lead/manag level would fine senior . If like job weari experi requir , ask hire manager/recruit post . everi compani differ way test knowledg . So far I 've taken data scienc time assess ( outsid resourc ) , complet take-hom assess ( 48 hour dataset ) , present past project 30 minut , differ compani . Be prepar anyth , use test clue cultur . for , I love take-hom test present give chanc show I know without much pressur . compani start open back . mani job post taken march-may , today number open expand rapidli . region may big factor . the compani I interview stuck either virtual , major virtual one in-person interview mask social distanc . ​ best luck everyon job search !
3|CareerList of Paid Machine Learning and Data Science Courses/E Books For FREE (self.datascience)|thecodingfossil|5|25|"Hello everyone,
I'm sharing some Paid Machine Learning and Data Science Courses and E Books which I found to be free. Personally I haven't completed any of them and they appear to be relatively new. Feel free to leave a review if someone has competed these before.
I personally feel like they are using this ""free enrollment"" system just to grab the first few hundred students. But since it doesn't cost us anything and since these people have created some nice courses before, it might be a good chance to get free access.
Hope these will help you to stay productive at home and learn machine learning skills!
https://medium.com/@rajmalhotra_2822/list-of-paid-machine-learning-and-data-science-courses-and-e-books-for-free-c34b9fc29eb0
"|hello everyon , I 'm share paid machin learn data scienc cours E book I found free . person I n't complet appear rel new . feel free leav review someon compet . I person feel like use `` free enrol '' system grab first hundr student . but sinc n't cost us anyth sinc peopl creat nice cours , might good chanc get free access . hope help stay product home learn machin learn skill ! http : //medium.com/ @ rajmalhotra_2822/list-of-paid-machine-learning-and-data-science-courses-and-e-books-for-free-c34b9fc29eb0
4|DiscussionDo you code in Object Oriented way in Python when doing data analytics? (self.datascience)|engineheat|146|266|"I just never got into the habit of writing object oriented code for data science, nor do I see a need. What's your thought?
The reason I'm asking is because someone asked to see my code for a data science role, and I'm starting to doubt myself. I might fix up my code a bit, and wants to hear some advice on what to watch out for.
thanks
PS: do you know where I can look at some good coding examples in data science?
"|I never got habit write object orient code data scienc , I see need . what 's thought ? the reason I 'm ask someon ask see code data scienc role , I 'm start doubt . I might fix code bit , want hear advic watch . thank PS : know I look good code exampl data scienc ?
5|DiscussionProfessional data scientists: did you overcome the feeling of never knowing enough? If so, how? (self.datascience)|wtfzambo|6|none|"Hello!
I'm a junior data scientist, been working in the field for about a year after getting a professional master in this topic.
I work for a small startup, which means that I have no mentor and I have to figure out shit on my own, as well as deal with everything that is data related (not just data science, but also engineering, ETL and what not).
It's fun and challenging, but also at times very frustrating, because I have this constant feeling of never knowing enough, and given the complexity and depth of this field, and the pace at which it develops, it is really overwhelming.
Also, coming from a business / economics background, my math and stats skills are not exactly razor sharp.
I compensate by being a massive nerd, so I learn stuff quickly, but that's about it.
Advice?
"|hello ! I 'm junior data scientist , work field year get profession master topic . I work small startup , mean I mentor I figur shit , well deal everyth data relat ( data scienc , also engin , etl ) . It 's fun challeng , also time frustrat , I constant feel never know enough , given complex depth field , pace develop , realli overwhelm . also , come busi / econom background , math stat skill exactli razor sharp . I compens massiv nerd , I learn stuff quickli , 's . advic ?
6|DiscussionWhat is in your model check list? (self.datascience)|goat211|4|11|"What are some of the things you do after fitting a model (i.e. regression or classification)? To understand the types of decisions it’s making, understand if it’s biased or overfitting, etc.? 
This is a pretty broad question but I’m looking to create a checklist of things that should be done ensure you have a “good model” 
Things like:
*Check the correlation between variables (heatmaps, VIF, etc.)
*Check the feature importance’s/model coefficients 
*Use SHAP values / charts to understand the directionality of model features 
*Plot the drop-off in accuracy when eliminating features (either through backward elimination or pruning the most important features) 
*Plotting interaction terms between your variables 
*Checking the model performance for different encoding strategies (one-hot, target encoding, etc) 
*Plotting performance by different subregions in your data  
*Compare different algorithms for performance
"|what thing fit model ( i.e . regress classif ) ? To understand type decis ’ make , understand ’ bias overfit , etc. ? thi pretti broad question I ’ look creat checklist thing done ensur “ good model ” thing like : *check correl variabl ( heatmap , vif , etc . ) *check featur import ’ s/model coeffici *use shap valu / chart understand direction model featur *plot drop-off accuraci elimin featur ( either backward elimin prune import featur ) *plot interact term variabl *check model perform differ encod strategi ( one-hot , target encod , etc ) *plot perform differ subregion data *compar differ algorithm perform
7|EducationWhat type of Master's degree should I pursue? (self.datascience)|Ihazpokemonz4u|1|3|"Hi guys, just some background before my main question: 
This summer I decided that software development is not for me and decided to pursue data science instead and fell in love with it. I'm currently an undergraduate student pursuing a major in Computer Science with a focus on AI and a minor in Statistics as well as a certificate from my school in Data Analytics. I tried to pick my major and minor to cover as many of the important skills in data science as possible on top of pursuing one of the optional yet relevant certificates offered by my school. I am also pursuing a couple MOOCs to teach me what I need to start developing a portfolio to hopefully secure an internship next summer (my internship this summer is as a backend web developer which is not directly useful).
Now, since I am entering my third semester I think now is a good time to start planning for my graduate degree. I recently spoke to an academic adviser about this and they were suggesting that I pursue one of the master's options from my school (understandably) in Computer Science. Specifically of interest was the research based program for Artificial Intelligence. However, the school also offers a course based Master's in Management Analytics which seems like it would give me me many of the data skills I am looking for as well as provide some business knowledge that I am lacking in my current degree. 
These options are obviously from my school only and I am more than willing to go elsewhere for my graduate studies but I had some questions with regards to my options.

Should I prefer a research-based, project-based, or course-based master's? My biggest concern with research based would be coming up with an idea for my thesis. Are Master's students expected to develop their own proposal or will I typically be working with a professor to come up with an idea?
What field would be best to get my master's in? Specifically considering my undergraduate degree (CS major, Stats minor) would it be best to pursue another CS master's or should I pursue something from Mathematics, Statistics, Data Science or anything else? It seems like Data Science would be an obvious choice but I'm from Canada and I don't have too many options with regards to Data Science programs.

"|Hi guy , background main question : thi summer I decid softwar develop decid pursu data scienc instead fell love . I 'm current undergradu student pursu major comput scienc focu AI minor statist well certif school data analyt . I tri pick major minor cover mani import skill data scienc possibl top pursu one option yet relev certif offer school . I also pursu coupl mooc teach I need start develop portfolio hope secur internship next summer ( internship summer backend web develop directli use ) . now , sinc I enter third semest I think good time start plan graduat degre . I recent spoke academ advis suggest I pursu one master 's option school ( understand ) comput scienc . specif interest research base program artifici intellig . howev , school also offer cours base master 's manag analyt seem like would give mani data skill I look well provid busi knowledg I lack current degre . these option obvious school I will go elsewher graduat studi I question regard option . should I prefer research-bas , project-bas , course-bas master 's ? My biggest concern research base would come idea thesi . are master 's student expect develop propos I typic work professor come idea ? what field would best get master 's ? specif consid undergradu degre ( CS major , stat minor ) would best pursu anoth CS master 's I pursu someth mathemat , statist , data scienc anyth els ? It seem like data scienc would obviou choic I 'm canada I n't mani option regard data scienc program .
8|DiscussionOpinion needed on learning data science (self.datascience)|Natsucr7|1|none|"I have been doing a Udemy Course (Python for Data Science and Machine Learning) for 10 days now and I have finished one half of the course, which is basically the data analysis part using pandas and visualizing the data. The next part of the course involves machine learning. Should I stop here and look at Kaggle Projects and try to understand the machine learning process through reverse learning or should I try and continue the course?
"|I udemi cours ( python data scienc machin learn ) 10 day I finish one half cours , basic data analysi part use panda visual data . the next part cours involv machin learn . should I stop look kaggl project tri understand machin learn process revers learn I tri continu cours ?
9|EducationHow much Mathematics does a Data Analyst need to know compared to a Data Scientist? (self.datascience)|WrathOfChevy|0|none|"I ask, because I've only got a good grasp on basic Statistics & College Algebra. And I'm interested in becoming a Data Analyst. 
I understand that the leap from Data Analyst  > Data Scientist is a large one. Meaning there is a serious amount of knowledge needed to move from the former to the latter. 
I of course plan on studying more and more as I go on in the future, but ""how much"" math does one need to know to become a Data Analyst?
"|I ask , I 've got good grasp basic statist & colleg algebra . and I 'm interest becom data analyst . I understand leap data analyst > data scientist larg one . mean seriou amount knowledg need move former latter . I cours plan studi I go futur , `` much '' math one need know becom data analyst ?
10|DiscussionQuestion: Why isn't there more linear regression with Nth degree polynomials? (self.datascience)|mathfordata|1|none|"I feel like whenever I see linear regression models, I rarely see them use anything other than first degree regressors. Is there a reason we don't use more 2nd or 3rd degree regressors? 
e.g. housing_price = B1*bathrooms + B2*bathrooms^2 + B3*bedrooms 
Maybe this has just been my experience, I just feel like we're making a huge assumption that the relation is linear and not quadratic or what have you. Also, as a data scientist, would you just try a variable up to some degree and keep the significant terms, or should you have reason to believe there is a relationship of that degree before trying it?
"|I feel like whenev I see linear regress model , I rare see use anyth first degre regressor . Is reason n't use 2nd 3rd degre regressor ? e.g . housing_pric = b1*bathroom + b2*bathrooms^2 + b3*bedroom mayb experi , I feel like 're make huge assumpt relat linear quadrat . also , data scientist , would tri variabl degre keep signific term , reason believ relationship degre tri ?
11|ToolingConditionally display a markdown cell in a Jupyter notebook (self.datascience)|ratterstinkle|1|1|"Does anyone know if you can have a markdown cell in a Jupyter notebook appear based on what is run in an executable cell? I want to have quiz questions that will show the solution, but only after they've tried to solve it on their own.
"|doe anyon know markdown cell jupyt notebook appear base run execut cell ? I want quiz question show solut , 've tri solv .
12|DiscussionBook Hunting (self.datascience)|kerrvature|1|2|"Hello people of reddit! I am Stella and this is my first post ^_^
So I am about to finish a Master's program from university on computational intelligence and I want to go deeper since I decided to take this seriously as a career scenario. I have a bachelor in Physics with a specialization on Astrophysics so research is the main area that I will go hunting for a job.
So I am between 2 books( both from O'reilly Publishing company ):

Python Data Science Handbook: Tools and Techniques for Developers by Wes Mckinney
Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems by Aurelien Geron

Is anyone familiar with either the books themselves/ Publishing company / authors that has something to add because this is a new area for me and I looking for feedback.
Do you have any book/tutorials recommendations?
Cheers
"|hello peopl reddit ! I stella first post ^_^ So I finish master 's program univers comput intellig I want go deeper sinc I decid take serious career scenario . I bachelor physic special astrophys research main area I go hunt job . So I 2 book ( o'reilli publish compani ) : python data scienc handbook : tool techniqu develop we mckinney hands-on machin learn scikit-learn , kera , tensorflow : concept , tool , techniqu build intellig system aurelien geron Is anyon familiar either book themselves/ publish compani / author someth add new area I look feedback . Do book/tutori recommend ? cheer
13|EducationWhy don't job postings ask for Data management / analytics degrees? (self.datascience)|WrathOfChevy|41|30|"This may be a silly question, but I notice that a lot of job postings are asking for ""Bachelor’s Degree or equivalent in Math, Information Systems, Computer Science, Engineering or related field "". 
All this time, I've been assuming that the Data management / Data analytics degree that I'm working on obtaining will fall into the ""Or related field"" category, but I'm asking this question, because I don't want to assume. 
Does anyone here have any insight on this? 
Do any of you have this particular degree?
If not, what are your opinions on this degree? (I'm working on getting this degree from WGU.)
"|thi may silli question , I notic lot job post ask `` bachelor ’ degre equival math , inform system , comput scienc , engin relat field `` . all time , I 've assum data manag / data analyt degre I 'm work obtain fall `` Or relat field '' categori , I 'm ask question , I n't want assum . doe anyon insight ? Do particular degre ? If , opinion degre ? ( I 'm work get degre wgu . )
14|DiscussionIs there any package or model available to translate any language into English offline? (self.datascience)|waheed0332|1|2|empty|empti
15|Job SearchIs the job market really fucked ? (self.datascience)|MicropylarCyclist|8|17|"Context : I’m an international student in the United States currently looking for an entry level job in data science. Due to covid-19 and it’s impact on the economy, I’ve been told by my batch mates and seniors who have graduated that it’s difficult/almost impossible to get a full time job right now. I’ll graduate next month after which I have till November/ December to get a job which offers sponsorship. Just want to know how much has hiring been affected in these circumstances for data science positions (data scientist, data analyst, business analyst, business intelligence analyst, risk analyst)
"|context : I ’ intern student unit state current look entri level job data scienc . due covid-19 ’ impact economi , I ’ told batch mate senior graduat ’ difficult/almost imposs get full time job right . I ’ graduat next month I till november/ decemb get job offer sponsorship . just want know much hire affect circumst data scienc posit ( data scientist , data analyst , busi analyst , busi intellig analyst , risk analyst )
16|ToolingInteresting R packages for experienced users (self.datascience)|autisticmice|8|5|"Hi, I want to compile a small list (for personal use) of interesting R packages that are worth checking out. I've been using R for many years and know most of the usual stuff (caret, tidyverse, packrat, ggplot, data.table,...), so I'd like to find packages that could help with more high-level concerns of a project, so to speak (say, reproducibility, iteration speed,..). For example I didn't know Drake until recently, and I thought it was an interesting thing to try. I hope this makes sense, and thanks in advance for any suggestion.
"|Hi , I want compil small list ( person use ) interest R packag worth check . I 've use R mani year know usual stuff ( caret , tidyvers , packrat , ggplot , data.t , ... ) , I 'd like find packag could help high-level concern project , speak ( say , reproduc , iter speed , .. ) . for exampl I n't know drake recent , I thought interest thing tri . I hope make sens , thank advanc suggest .
17|CareerMasters program for non-coder Managers who have working knowledge of ML/AI? (self.datascience)|GypsyFever|1|1|"I've worked as a marketing Analytics Manager/Director for ~5 years and have taken a 10-week Python ccourse along with having fairly extensive knowledge of ML, it's applications, and ideal outputs.
I'm wondering if there is a masters course designed to prep more senior analyts/directors for managing a data science team. Or a course that may not be specifically tailored but would be a good fit for advancing Data Science skills?
"|I 've work market analyt manager/director ~5 year taken 10-week python ccours along fairli extens knowledg ML , 's applic , ideal output . I 'm wonder master cours design prep senior analyts/director manag data scienc team . Or cours may specif tailor would good fit advanc data scienc skill ?
18|CareerCareer advice as my coop comes to a close (self.datascience)|AndriodFanBoy|0|1|"Background:
Hey guys, long time lurker first time poster so please bare with me. I am currently a  sophomore student at UTD who is majoring in ITS , who will be completing his fist professional level job in August. I have been working at American Airlines as a junior Data analyst for what will be 8 months in August. and as its quickly approaching, my concern for life post coop are growing.  Before getting this coop, I could barely support myself financially and so I have been making the most of my coop income by paying off debt, but as I look at what I was making pre coop I am realizing that my debt reduction rate at the moment still wont reduce my monthly expenses enough to were I will be able to sustain myself.   
Question: 
While working at AA, I learned python, machine learning, sql, and neural networks for the most part and I am wanting to know given the pandemic and my financial situation how do I best prepare myself now so that I have a fighting chance to make a transition from AA to another job in my field?  What should I be focusing my extra time on so that when the coop ends i can land preferably a part time jr data analyst position or something similar?
"|background : hey guy , long time lurker first time poster pleas bare . I current sophomor student utd major it , complet fist profession level job august . I work american airlin junior data analyst 8 month august . quickli approach , concern life post coop grow . befor get coop , I could bare support financi I make coop incom pay debt , I look I make pre coop I realiz debt reduct rate moment still wont reduc monthli expens enough I abl sustain . question : while work AA , I learn python , machin learn , sql , neural network part I want know given pandem financi situat I best prepar I fight chanc make transit AA anoth job field ? what I focus extra time coop end land prefer part time jr data analyst posit someth similar ?
19|CareerML within Cyber Security (self.datascience)|steph_back41|4|3|"Does anyone work in machine learning in the cyber security domain? I am curious about opportunities in it. I know that ML is used heavily in CS but just curious about insider info from people working in the industry.
"|doe anyon work machin learn cyber secur domain ? I curiou opportun . I know ML use heavili CS curiou insid info peopl work industri .
20|NetworkingML.NET community (self.datascience)|bush_dev|1|4|"Hello guys!
I just created space for people interested in ML.NET library, I encourage you to join there!
https://www.reddit.com/r/ml_dotnet/
"|hello guy ! I creat space peopl interest ml.net librari , I encourag join ! http : //www.reddit.com/r/ml_dotnet/
21|DiscussionHow do I interpret this learning curve? Is this a case of high bias or high variance? (self.datascience)|iCHAIT|1|2|"Hi All,
I am working on a problem of binary classification. With a pretty small data set (100 observations, 21 features, and 70-30 target split)
Using cross-validation I found LogisticRegression (with liblinear and l1 penalty) to work best, giving my high AUC score (my metric of focus for the project). Please note that l1 penalty shrank all of the features except for 2.
I plotted the learning curve to understand how to proceed next. Here is the plot - https://i.imgur.com/Vm224zi.png
My problem is I am not able to interpret this plot. Is this a case of high bias or high variance? And why so?
Note: Y-axis denotes AUC Score
Here is the code I used to get the learning curve params (if it helps) - 

train_sizes, train_scores, test_scores = learning_curve(LogisticRegression(penalty='l1', solver = 'liblinear'), 
                                                        X, y, cv=10, shuffle=True
                                                        , scoring='roc_auc'
                                                       )

Please Help
"|Hi all , I work problem binari classif . with pretti small data set ( 100 observ , 21 featur , 70-30 target split ) use cross-valid I found logisticregress ( liblinear l1 penalti ) work best , give high auc score ( metric focu project ) . pleas note l1 penalti shrank featur except 2 . I plot learn curv understand proceed next . here plot - http : //i.imgur.com/vm224zi.png My problem I abl interpret plot . Is case high bia high varianc ? and ? note : y-axi denot auc score here code I use get learn curv param ( help ) - train_siz , train_scor , test_scor = learning_curv ( logisticregress ( penalty='l1 ' , solver = 'liblinear ' ) , X , , cv=10 , shuffle=tru , scoring='roc_auc' ) pleas help
22|CareerImportance of domain expertise to career growth (self.datascience)|dmorris87|5|10|"How important is it to develop domain expertise? I'm struggling a bit right now because I've focused my past efforts on gaining general knowledge (e.g. universal time series forecasting strategies) instead of domain knowledge. As a result, I feel more like a consultant at times. What do you think are the career advantages/disadvantages to this?
"|how import develop domain expertis ? I 'm struggl bit right I 've focus past effort gain gener knowledg ( e.g . univers time seri forecast strategi ) instead domain knowledg . As result , I feel like consult time . what think career advantages/disadvantag ?
23|DiscussionSpyder IDE Markdown (self.datascience)|The_Doc_P|15|27|"Anybody have a way to create markdowns within Spyder IDE? Most reporting I've done in the past is in R using RMarkdown, knitr, etc and have not had the need to use Spyder for creating a markdown report before. I looked into spyder-reports and am not sure if that is still functioning. Any suggestions would be appreciated!
"|anybodi way creat markdown within spyder ide ? most report I 've done past R use rmarkdown , knitr , etc need use spyder creat markdown report . I look spyder-report sure still function . ani suggest would appreci !
24|DiscussionNew to Data Science (self.datascience)|dingdonggamer19|4|2|"I am completely new to data science with a business background(entrepreneurship + diploma certificate). I am 19 and I found a passion for Data Science. I am thinking to go for a Mathematics and Statistics Degree.
I am currently learning Python, heading on to R soon. I have a module on tableau and am quite efficient on it. Any suggestions on what softwares and skill to learn?
My research led me mainly to Kaggle, SQL, Machine Learning, SAS and Spark. Anything else to add on and is there a specific order to learning these?
"|I complet new data scienc busi background ( entrepreneurship + diploma certif ) . I 19 I found passion data scienc . I think go mathemat statist degre . I current learn python , head R soon . I modul tableau quit effici . ani suggest softwar skill learn ? My research led mainli kaggl , sql , machin learn , sa spark . anyth els add specif order learn ?
25|CareerAgile/scum is... the worst? (self.datascience)|therockhound|125|378|"I feel micromanaged and like I am expected to do analysis like an engineer churns out code. Daily stand ups, retros, bleh. There is also a sharp divide between ""product owners"" and worker bees who execute someone else's vision, so all my time is accounted for. No room to scope/source new projects at all.
What I love about analytics/data science and where my true value lies is defining problems and creatively working with stakeholders to solve them.
Does anyone have any recommendations about industries/companies/job titles to explore that give data scientists the scope to come up with new projects and where there isn't a strong product owner/technical divide?
Edit: Wow data people. Thanks for the responses! Been really interesting to read the diverging opinions and advice. My takeaway is that there can be a time and a place for these tools and perhaps the explanatory variable is management and company culture. Personally, I will try to be the change in my org that makes these processes work better. Thanks for enlightening me and breaking me out of my mental local minimum.
"|I feel micromanag like I expect analysi like engin churn code . daili stand up , retro , bleh . there also sharp divid `` product owner '' worker bee execut someon els 's vision , time account . No room scope/sourc new project . what I love analytics/data scienc true valu lie defin problem creativ work stakehold solv . doe anyon recommend industries/companies/job titl explor give data scientist scope come new project n't strong product owner/techn divid ? edit : wow data peopl . thank respons ! been realli interest read diverg opinion advic . My takeaway time place tool perhap explanatori variabl manag compani cultur . person , I tri chang org make process work better . thank enlighten break mental local minimum .
26|EducationHas anyone taken the U of T Austin online Post Graduate Program in Data Science and Business Analytics? (self.datascience)|MattyH51|0|2|"Hi all, I started python about two months ago and came across this course and saw that UT austin was ranked 2nd for data science/ analytics. Has anyone taken this course and if so would you recommend it? My plan is to practise my python until late august early sept and then apply.  I guess I'm also curious about the knowledge level I should have going into this so I'm not just stuck on the basics.
​
Thank you in advance!!!
"|Hi , I start python two month ago came across cours saw UT austin rank 2nd data science/ analyt . ha anyon taken cours would recommend ? My plan practis python late august earli sept appli . I guess I 'm also curiou knowledg level I go I 'm stuck basic . ​ thank advanc ! ! !
27|DiscussionNew website for ADSA (self.datascience)|flushingborn|0|11|"Has anyone seen that ADSA just relaunched their website? It's looking pretty good. 
https://academicdatascience.org/
EDIT: added URL
"|ha anyon seen adsa relaunch websit ? It 's look pretti good . http : //academicdatascience.org/ edit : ad url
28|DiscussionWhat work you are actually doing when your title is data scientist? (self.datascience)|addictzz|3|2|"I wonder what work are people actually doing under the data scientist title?
For me, I am doing a spectrum of technical-related data activties such as data cleaning, data pipeline building, data analysis, ML modelling, and data-driven company's internal improvement. I realized that in other companies, some DS mostly do ML modelling, some are doing data product building, and some are doing entirely data cleaning. It depends on how company sees the benefit of data people.
I begin to feel that data scientist is an umbrella term for everything data-related.
So I am wondering what actual work you are doing with this title?
Maybe my goal with this thread is to crowdsource information on how company is utilizing data-savvy people and what data related activities that a company is having.
"|I wonder work peopl actual data scientist titl ? for , I spectrum technical-rel data activti data clean , data pipelin build , data analysi , ML model , data-driven compani 's intern improv . I realiz compani , DS mostli ML model , data product build , entir data clean . It depend compani see benefit data peopl . I begin feel data scientist umbrella term everyth data-rel . So I wonder actual work titl ? mayb goal thread crowdsourc inform compani util data-savvi peopl data relat activ compani .
29|DiscussionHow to evaluate a model performance after deploying into production? (self.datascience)|shonesum|14|13|"How do we evaluate the model performance after it is deployed? If it was normal prediction model, we could evaluate based on the actual outcome. However if there is outside interference to change the outcome of that model, how can we evaluate it? When I talk about outside interference. I mean someone takes some action so that that prediction doesn’t occur. Eg we are predicting if an apple will rot, if the prediction is greater than 60% we do something so that the apple will not rot. How can we measure the model performance? How can we know if the prediction was correct?
"|how evalu model perform deploy ? If normal predict model , could evalu base actual outcom . howev outsid interfer chang outcom model , evalu ? when I talk outsid interfer . I mean someon take action predict ’ occur . Eg predict appl rot , predict greater 60 % someth appl rot . how measur model perform ? how know predict correct ?
30|CareerHow to Advance my Understanding of Deep Learning/Computer Vision (self.datascience)|Stutoucan12|1|1|"Hello, 
I just finished ""hands on ml with scikit learn and tensorflow"" and I loved it. I really want to advance my understanding of CNNs, but I don't know what steps to take next. 
- I've heard great things about the ""Deep Learning with Python"" book by Francois Chollet
- I've done stuff in Kaggle, but I am still at the stage where I need some structure
- Perhaps I could read state-of-the-art research papers and document my understandings
​
- How would you guys  suggest I get my hands dirty?
"|hello , I finish `` hand ml scikit learn tensorflow '' I love . I realli want advanc understand cnn , I n't know step take next . - I 've heard great thing `` deep learn python '' book francoi chollet - I 've done stuff kaggl , I still stage I need structur - perhap I could read state-of-the-art research paper document understand ​ - how would guy suggest I get hand dirti ?
31|DiscussionAdvice in B2B Sales Analysis (self.datascience)|butteryflakycrus|10|5|"I work in a B2B sales organization and our Director of Sales wants me to find the commonalities between the companies that each sales rep has had success selling to. I have data where each observation is a company the sales rep tried to sell to (opportunity), the characteristics (qual. and quant.) of the company, and the outcome (won/lost). Below are a few ideas I had on tackling this question, but I am wondering how you would approach this. 

Use a factor analysis method on the won opportunities for a sales rep and analyze the axes with low explanation of variance. Would this essentially tell me what makes these companies the same, as opposed to different? 
Use logistic regression with all the opportunities and analyze the significant variables that increase the probability of winning.

"|I work b2b sale organ director sale want find common compani sale rep success sell . I data observ compani sale rep tri sell ( opportun ) , characterist ( qual . quant . ) compani , outcom ( won/lost ) . below idea I tackl question , I wonder would approach . use factor analysi method opportun sale rep analyz axe low explan varianc . would essenti tell make compani , oppos differ ? use logist regress opportun analyz signific variabl increas probabl win .
32|DiscussionDoes anyone use or came across weighted least square or robust regression in their work? (self.datascience)|bot_cereal|3|2|"I am wondering if anyone use technique like Weighted Least Square or robust regression in their work. How does these models stack up against tree-based model, regularized model, or other ml model?
​
I also posted the question in stackexchange.
https://stats.stackexchange.com/questions/470044/when-does-we-use-weighted-ls-regression-generalized-ls-regression-or-robust-re
"|I wonder anyon use techniqu like weight least squar robust regress work . how model stack tree-bas model , regular model , ml model ? ​ I also post question stackexchang . http : //stats.stackexchange.com/questions/470044/when-does-we-use-weighted-ls-regression-generalized-ls-regression-or-robust-r
33|DiscussionExperiments with infrequently updating metrics (self.datascience)|da_chosen1|1|2|"I'm trying to run an experiment, and the lag time to measure the impact of the experiment is about 4 months.  Has anyone come across this problem?
"|I 'm tri run experi , lag time measur impact experi 4 month . ha anyon come across problem ?
34|DiscussionHow do you approach ML/ DS problem? (self.datascience)|pratikkejriwal|4|3|"Hi folks! I am currently working as a Software Engineer in a Reporting/Analysis team using SAP BO and SQL. I am trying to get a job as a data scientist and had applied to a bunch of companies and did attend interview in a few. In the last interview which I gave, the interviewer asked me the above question, and I couldn't say anything which was able to convince him.
I have taken a bunch of MOOC courses and had worked on common UCI datasets. I have recently started with Kaggle as well (trying the basic one's right now). I know I have to improve a lot, but this question keeps on pondering me, as the interviewer was okay with me working with iris dataset as I am fresher with less than 1 year of full-time experience. He just wanted to know my answer to the above question. I tried thinking and giving a generalized answer but he wasn't impressed and asked how did you solve iris problem. Having watched n number of tutorials, the bias kicked in and I just said that I need to do EDA, understand the relationship between parameters and then go about solving the problem by applying, any of the many Classification algorithm, which I had done.
But he wasn't having it and this got me thinking that in the real-world you won't be given a dataset to work with, forget about proper expectation/requirement. And you cannot waste/invest a lot of time doing EDA as the client is looking for a working model and not a bunch of graphs and visualizations, so how to actually approach a ML/DS problem?
Can some of the folks working in the field describe to me, as how would have you answered the above question and typical tasks or problem statement you get during your job and your thought process in approaching the task.
thanks for your time, much appreciated :)
"|Hi folk ! I current work softwar engin reporting/analysi team use sap BO sql . I tri get job data scientist appli bunch compani attend interview . In last interview I gave , interview ask question , I could n't say anyth abl convinc . I taken bunch mooc cours work common uci dataset . I recent start kaggl well ( tri basic one 's right ) . I know I improv lot , question keep ponder , interview okay work iri dataset I fresher less 1 year full-tim experi . He want know answer question . I tri think give gener answer n't impress ask solv iri problem . have watch n number tutori , bia kick I said I need eda , understand relationship paramet go solv problem appli , mani classif algorithm , I done . but n't got think real-world wo n't given dataset work , forget proper expectation/requir . and waste/invest lot time eda client look work model bunch graph visual , actual approach ml/d problem ? can folk work field describ , would answer question typic task problem statement get job thought process approach task . thank time , much appreci : )
35|Educationwhere can i find detailed solutions for kaggle courses? (self.datascience)|thessain|3|9|"hello guys i am struggling a little with the kaggle courses in deep learning to fully understand every part of the code are there more detailed solutions anywhere to be found apart from the kaggle site itself? i couldnt find it in google thanks alot
"|hello guy struggl littl kaggl cours deep learn fulli understand everi part code detail solut anywher found apart kaggl site ? couldnt find googl thank alot
36|DiscussionHow to proceed after the cross-validation step? (self.datascience)|arke47|12|7|"Hi All,
I am pretty new to data science so pardon me if this is a silly question. 
So I am working on a binary classification problem and found out that Logistic Regression works best for my dataset based on 10 fold cross-validation accuracy score.  (Mean acc = 93.5%)
Now, I want to put a model into production to actually make some kind of prediction on future incoming data. 
Which model do I put into production? When I split my data into training and test and train the model it gives me different accuracy each time. I understand why that is happening. But when it comes to deploying this Logistic Regression model, what do i do?
"|Hi all , I pretti new data scienc pardon silli question . So I work binari classif problem found logist regress work best dataset base 10 fold cross-valid accuraci score . ( mean acc = 93.5 % ) now , I want put model product actual make kind predict futur incom data . which model I put product ? when I split data train test train model give differ accuraci time . I understand happen . but come deploy logist regress model , ?
37|ProjectsQuestion on gathering data (self.datascience)|SeaLadder222|6|4|"I am trying to use scrape data off of https://www.trip.com/travel-restrictions-covid-19/ so I can make a spreadsheet of what countries require quarantines, the specific countries that are banned from travelling to another country, etc. I am having trouble of thinking of ways for gathering the data. I don't see any common patterns in the language I can use so I am not sure if entering manual rules to collect the data is possible. Does anyone know of good strategies for parsing the data?
"|I tri use scrape data http : //www.trip.com/travel-restrictions-covid-19/ I make spreadsheet countri requir quarantin , specif countri ban travel anoth countri , etc . I troubl think way gather data . I n't see common pattern languag I use I sure enter manual rule collect data possibl . doe anyon know good strategi pars data ?
38|DiscussionHas anyone ever used a logistic regression to try and predict dividend payments? (self.datascience)|Quippykisset|9|0|empty|empti
39|DiscussionSo many people disappointed with their jobs. You need to manage your expectations, especially if you're very junior. (self.datascience)|MonthyPythonista|101|633|"​
I keep seeing threads on this forum about how disappointed so many people are with their data science jobs.
​
I think expectations need to be managed, in any line of work:

Seniority / juniority:  When you start as a medical doctor, you won't start by diagnosing Dr. House-like rare, life-threatening conditions straight away. If you join a law firm, you won't start by passionately and single-handedly defending your clients in court like in a John Grisham book. If you join Goldman Sachs as a graduate, you won't start by managing multi-billion trades and investments straight away. Any job has a certain amount of grunt work, which is greater at the very beginning of your career. The world is full of bright kids disappointed with their first jobs, wondering: ""did I really study 3/4/5 years to change the colours of a PowerPoint slide?"".
Importance within the organisation: this varies wildly from place to place but, generally, regardless of the guff HR says, in many organisations there is a clear difference in the food chain between the functions which are seen as generating revenues and those which are seen as support functions. In many places, the sales team (or equivalent) brings home the money, and everyone else is seen as a support function. You don't need to argue with me that this is shortsighted: you need to understand that this attitude is common, need to do your homework on what the culture is like before joining a company, and make your decisions accordingly.
(related to #2): what is the background of the senior people? If you are a data scientist in a company where most senior executives have some kind of technical background, you are more likely to be appreciated than in a company where the senior guys (it's almost always guys...) are all salespeople who go into sensory shutdown the moment you mention anything more complicated than the times tables.
what are the real needs of the business? Even in the most enlightened organisation, with the most technical sensible competent open-minded etc etc executives, there will be more need for boring work than for exciting, cutting-edge work. For every person that must do proper R&D and brand-new, cutting edge models processes technologies etc, there will need to be many more people that must manage and maintain the existing processes and models, which is important even if less interesting

"|​ I keep see thread forum disappoint mani peopl data scienc job . ​ I think expect need manag , line work : senior / junior : when start medic doctor , wo n't start diagnos dr. house-lik rare , life-threaten condit straight away . If join law firm , wo n't start passion single-handedli defend client court like john grisham book . If join goldman sach graduat , wo n't start manag multi-billion trade invest straight away . ani job certain amount grunt work , greater begin career . the world full bright kid disappoint first job , wonder : `` I realli studi 3/4/5 year chang colour powerpoint slide ? '' . import within organis : vari wildli place place , gener , regardless guff HR say , mani organis clear differ food chain function seen gener revenu seen support function . In mani place , sale team ( equival ) bring home money , everyon els seen support function . you n't need argu shortsight : need understand attitud common , need homework cultur like join compani , make decis accordingli . ( relat # 2 ) : background senior peopl ? If data scientist compani senior execut kind technic background , like appreci compani senior guy ( 's almost alway guy ... ) salespeopl go sensori shutdown moment mention anyth complic time tabl . real need busi ? even enlighten organis , technic sensibl compet open-mind etc etc execut , need bore work excit , cutting-edg work . for everi person must proper R & D brand-new , cut edg model process technolog etc , need mani peopl must manag maintain exist process model , import even less interest
40|EducationOklahoma State University MSBAnDS (self.datascience)|ElectronicQuarter|3|0|"Does anyone know if the Masters in Business Analytics and Data Science program at Oklahoma State University is any good? What is the reputation of the program? I recently got accepted and I’m trying to decide if I should enroll. I’m feeling some hesitation due to the lack of information online regarding this program. Has anyone attended? Any experience or knowledge you can share is appreciated. If you have any recommendations for good online data science or analytics masters programs, that’d be great too!
"|doe anyon know master busi analyt data scienc program oklahoma state univers good ? what reput program ? I recent got accept I ’ tri decid I enrol . I ’ feel hesit due lack inform onlin regard program . ha anyon attend ? ani experi knowledg share appreci . If recommend good onlin data scienc analyt master program , ’ great !
41|Frameworks to assess impact of models (self.datascience)|Lechateau|6|1|"Hello everyone, this is a little spot where I've learned a lot. After a few searches I could not find something that could help me learn about how to assess quantitatively the impact of a model.
Do you have any literature/video/article suggestions that I could put my attention to?
Thank you so much for your time.
"|hello everyon , littl spot I 've learn lot . after search I could find someth could help learn assess quantit impact model . Do literature/video/articl suggest I could put attent ? thank much time .
42|DiscussionHow is a potential recruiter going to evaluate projects as original work and not just a replica of an already existing work? (self.datascience)|SuryadayN|5|1|"Trying to foray into DS. So, I am thinking of picking up a few projects like Sentiment analysis, fake news detection, speech emotion recognition etc to better my profile. But the codes for all these projects already exists on the net and tbh, I am going to refer them while creating my projects. What I am wondering is in doing so, where's the originality in these projects since anyone can copy the codes from the Internet and claim that they have done x project in their portfolio. Or are these projects too lame to even being considered as portfolio material?
"|tri foray DS . So , I think pick project like sentiment analysi , fake news detect , speech emot recognit etc better profil . but code project alreadi exist net tbh , I go refer creat project . what I wonder , 's origin project sinc anyon copi code internet claim done x project portfolio . Or project lame even consid portfolio materi ?
43|DiscussionHow to best calculate uplift from web traffic data? (self.datascience)|Yojihito|2|3|"Did someone already build a model (not necessariliy DS but plain DA/calculations) to get Uplift value from marketing campaigns (e.g. TV) onto web traffic in Corona times and can talk about a bit about it?
I see a lot of spikes and a mismatching baseline due to increased Corona online shopping and wonder how I can calculate a new, good fitting baseline?
"|did someon alreadi build model ( necessariliy DS plain da/calcul ) get uplift valu market campaign ( e.g . TV ) onto web traffic corona time talk bit ? I see lot spike mismatch baselin due increas corona onlin shop wonder I calcul new , good fit baselin ?
44|DiscussionDo less Data Science (self.datascience)|expatwithajetpack|38|253|"That's why we're all here, right? 
I'd like to share with you a nice little story. I've recently been working on a difficult scoring problem that determined a rank from numerous features. There were numerous issues: which features were most important, did it make sense to have so many features, do we condense them, do we take the mean and so on. I had been working on this problem for weeks, and after numerous measurements, reports, reading and testing, I conked out -- I gave up. 
Man, Data Science was done for me; I was so over it. I started talking more with my colleagues in different departments, primarily in PR. I just felt like doing something else for a few days. I asked one of my colleagues in PR, ""so, what would you do if you had to rank X, Y, and Z?"" ""Hmm... I'm not so sure, I think I would be more interested in Z than X, why is X even necessary?"" She was right. Statistically, X was absolutely necessary in many of my modes. My boss thought this was the key to solving our problem, why would she think it's unnecessary? It turns out... as Data Scientists, we weren't the ones using the product. My colleague -- bless her soul -- is exactly our target audience. We were so in solutions mode, we forgot to just think about the problem and WHOM it concerns. 
I decided to take a walk and put pen to paper. I even asked the barista at the local cafe. It was so obvious. 
We were solving the WRONG problem the whole time -- well, at least we weren't making it any easier for ourselves.
To all of the great DS minds out there, sometimes we need to stop and reset. 
Problems are realised in different ways; it's our job as Data Scientists to understand who the realisation is for. 
Now, I'd love to know what your experiences were and how simplicity overcame complexity?
"|that 's 're , right ? I 'd like share nice littl stori . I 've recent work difficult score problem determin rank numer featur . there numer issu : featur import , make sens mani featur , condens , take mean . I work problem week , numer measur , report , read test , I conk -- I gave . man , data scienc done ; I . I start talk colleagu differ depart , primarili PR . I felt like someth els day . I ask one colleagu PR , `` , would rank X , Y , Z ? '' `` hmm ... I 'm sure , I think I would interest Z X , X even necessari ? '' she right . statist , X absolut necessari mani mode . My boss thought key solv problem , would think 's unnecessari ? It turn ... data scientist , n't one use product . My colleagu -- bless soul -- exactli target audienc . We solut mode , forgot think problem whom concern . I decid take walk put pen paper . I even ask barista local cafe . It obviou . We solv wrong problem whole time -- well , least n't make easier . To great DS mind , sometim need stop reset . problem realis differ way ; 's job data scientist understand realis . now , I 'd love know experi simplic overcam complex ?
45|DiscussionOpenAI – Learning Dexterity End-to-End - Experiment Report (self.datascience)|0_marauders_0|1|1|"Today OpenAI published a Weights & Biases Report (here) on some recent work done by the Robotics team at OpenAI where they trained a policy to manipulate objects with a robotic hand in an end-to-end manner. Specifically, they solved the block reorientation task from our 2018 release ""Learning Dexterity"" using a policy with image inputs rather than training separate vision and policy models (as in the original release).
In the report they describe their experimental process in general and then detail the findings of this specific work. In particular, they contrast the use of Behavioral Cloning and Reinforcement Learning for this task, and ablate several aspects of our setup including model architecture, batch size, etc.
Alex and I happy to discuss this and answer any questions about it.
"|today openai publish weight & bias report ( ) recent work done robot team openai train polici manipul object robot hand end-to-end manner . specif , solv block reorient task 2018 releas `` learn dexter '' use polici imag input rather train separ vision polici model ( origin releas ) . In report describ experiment process gener detail find specif work . In particular , contrast use behavior clone reinforc learn task , ablat sever aspect setup includ model architectur , batch size , etc . alex I happi discuss answer question .
46|ToolingAt what point do you stop with a clustering problem? (self.datascience)|expatwithajetpack|50|118|"Hey guys, 
So we’re looking to cluster our social demographic data. I’m pretty new to clustering validation and when to say, “this is good enough.” 
We have no pre labeled data to test our clusters,  only silhouette scores of ~ 0.65
At what point do I stop optimizing clustering problems, or is it subjective? 
For some background on the problem: 
We aim to label the data into 5~6 clusters (domain knowledge from my boss suggests in theory there should be 5~6 categories. Will discuss with him more), 
We wish to use the data to synthesize new data. I’m not too sure how we will achieve this, maybe a variational Autoencoder, or we simply find the closest centroid for data of our choice and sample from the centroid (this is the added restriction that our data is distributed in different ways as we are working with real estate data)
Given the problem, I’d say it’s important we have very clearly defined clusters, but
I’m just getting my head in a real knot knowing when it’s good enough, and my boss has said it’s entirely up to me. 
Thanks guys!
"|hey guy , So ’ look cluster social demograph data . I ’ pretti new cluster valid say , “ good enough. ” We pre label data test cluster , silhouett score ~ 0.65 At point I stop optim cluster problem , subject ? for background problem : We aim label data 5~6 cluster ( domain knowledg boss suggest theori 5~6 categori . will discuss ) , We wish use data synthes new data . I ’ sure achiev , mayb variat autoencod , simpli find closest centroid data choic sampl centroid ( ad restrict data distribut differ way work real estat data ) given problem , I ’ say ’ import clearli defin cluster , I ’ get head real knot know ’ good enough , boss said ’ entir . thank guy !
47|ProjectsReal World Data Collection (self.datascience)|za0880|15|10|"Hi, I am a recent college grad and I majored in data science so I have taken my fair share of courses and projects in machine learning and statistics. However, most, if not all of the projects I do in school and even the personal projects I work on the data is very readily available and in decent shape where I just need to do some cleaning and manipulation of the data.
Currently, I am working on a project where I am trying to process emails and build a type of importance algorithm based on the contents/data of the email.
The emails contain sensitive information and the preliminary dataset I have been testing on (very small size, <100 emails) has any sensitive info redacted which is fine. But when I get to the point where I will need tens of thousands of emails it is extremely impractical to redact each one.
I was wondering if anyone has any ideas of ways to build a model that either doesn't use the contents of the emails, or a way to deal with the sensitive information problem.
Thanks.
"|Hi , I recent colleg grad I major data scienc I taken fair share cours project machin learn statist . howev , , project I school even person project I work data readili avail decent shape I need clean manipul data . current , I work project I tri process email build type import algorithm base contents/data email . the email contain sensit inform preliminari dataset I test ( small size , < 100 email ) sensit info redact fine . but I get point I need ten thousand email extrem impract redact one . I wonder anyon idea way build model either n't use content email , way deal sensit inform problem . thank .
48|EducationExponential functions and optimisation (self.datascience)|Anonymushacker8|2|3|"Help with expotential functions
Hey guys,
I have a problem with expotentially rising weighting of allocations. I have a given:
total number of assets --> total
maximum allocation(in weights) --> max = .15
minimum allocation (in weights) -> min = 1/total/2
My goal is that the algortihm gives the first asset the maximum --> P(1|max),
The y value should be expotentially decreasing but should not be lower than min.
And the sum of weights should be close as possible to 1.
How can I accomplish that ?
--> I looked into scipy curve fitting, but I do not know how to apply it
"|"help expotenti function hey guy , I problem expotenti rise weight alloc . I given : total number asset -- > total maximum alloc ( weight ) -- > max = .15 minimum alloc ( weight ) - > min = 1/total/2 My goal algortihm give first asset maximum -- > P ( 1|max ) , the valu expotenti decreas lower min . and sum weight close possibl 1 . how I accomplish ? -- > I look scipi curv fit , I know appli"
49|DiscussionDoes anyone else that has been doing data science for a while find it incredibly boring? (self.datascience)|xbomber88|98|302|"I'm 5 years into my data science career and at my third job and I just find it incredibly boring and tedious and am thinking of leaving the field and moving into a software engineering role just to do something new.  I found it interesting in the beginning when I was learning new things but now it just seems like pretty much 95% of all data science work falls into moving data around, cleaning data, build a model by calling some outside machine learning library, or trying to explain things to business people.  I imagine there are some data science jobs out there where the work is interesting but they seem incredibly rare.  Have I just gotten unlucky in the jobs I've had or do other people who have been in the field for a while feel the same way as me?
"|I 'm 5 year data scienc career third job I find incred bore tediou think leav field move softwar engin role someth new . I found interest begin I learn new thing seem like pretti much 95 % data scienc work fall move data around , clean data , build model call outsid machin learn librari , tri explain thing busi peopl . I imagin data scienc job work interest seem incred rare . have I gotten unlucki job I 've peopl field feel way ?
50|DiscussionHow do you manage credentials/passwords for your data pipelines/ETL jobs? (self.datascience)|noun_verber|6|26|"Hello, first time system architect here. Or rather, I'm just the most experienced dev so they gave me the reins over the project architecture.
Anyway, we're building a data analytics platform and just finished our first pipeline that ETLs from a DB into our data warehouse. We were provided a read only account for that DB and initially, we saved the username and password in a gitignored credentials.ini file that we would manually copy paste during deployment.
We're about to start our second pipeline which will involve another DB and another set of credentials and it's becoming apparent that our project will eventually contain all the (read only) keys to the kingdom. We've switched to saving the credentials in a keepass vault (.kdbx) which is checked into our repository while manually copying the keyfile.
I understand that if we want these pipelines to be automated, those credentials are going to need to be accessible from within the system so really, I'm just wondering if there's a better way to manage the storage/deploying of them within our project.
We're using Python btw
"|hello , first time system architect . Or rather , I 'm experienc dev gave rein project architectur . anyway , 're build data analyt platform finish first pipelin etl DB data warehous . We provid read account DB initi , save usernam password gitignor credentials.ini file would manual copi past deploy . We 're start second pipelin involv anoth DB anoth set credenti 's becom appar project eventu contain ( read ) key kingdom . We 've switch save credenti keepass vault ( .kdbx ) check repositori manual copi keyfil . I understand want pipelin autom , credenti go need access within system realli , I 'm wonder 's better way manag storage/deploy within project . We 're use python btw
51|DiscussionData Science Ethic Issues Suggestions (self.datascience)|thebdup|8|1|"I'm in a data science ethics course over the summer. In a few weeks I'll be giving a 3-5 minute presentation that is supposed to serve as an overview on a data science ethics issue. I know that data science touches a lot of large, overarching domains such as privacy concerns, but I was hoping to find something specific and unique since many other people will be giving presentations as well. For example, in class we read through an article by Propublica about machine bias in court sentencing. 
Googling ""data science ethics topics"" seems to be a recipe for somewhat mundane articles that are overly broad. 
I'll happily take any suggestions anyone is offering or resources on where to look for topics such as this. 
Thank you.
"|I 'm data scienc ethic cours summer . In week I 'll give 3-5 minut present suppos serv overview data scienc ethic issu . I know data scienc touch lot larg , overarch domain privaci concern , I hope find someth specif uniqu sinc mani peopl give present well . for exampl , class read articl propublica machin bia court sentenc . googl `` data scienc ethic topic '' seem recip somewhat mundan articl overli broad . I 'll happili take suggest anyon offer resourc look topic . thank .
52|DiscussionI got the chance to interview a Data Scientist at Uber on their Shared Rides Team! (self.datascience)|ibsurvivors|40|430|"Hey guys -
Had the opportunity to interview a Data Scientist at Uber on their Shared Rides Team. Thought I'd share some of it here, in case you find it helpful :)
What do you do & where do you work?
My name is Divyansh Agarwal and I am a data scientist at Uber in San Francisco. I’m working on  the Shared Rides business, and work on building products that grow the business. Some of my work also involves optimizing the efficiency of Uber’s ride sharing marketplace by improving graph optimization algorithms for rider-driver matching, and evaluating their performance via experimentation and simulations.
When did you first become interested in Data Science?
So, I had an interest in machine learning and predictive analytics before going into university. I wrote about it in my college essays as well.
But I was also interested in software engineering and fields like security. What really made me truly interested in data science was taking Data 8 at UC Berkeley. I really liked the fact that you could use statistics to extract insights from data and provide value - and although I had always been aware of this, I only realized then how powerful statistics could be and how computing facilitates all of this.
After that, I started doing a bunch of projects, some internships, and got involved in research.
When applying for jobs, was it hard to choose between going for a software engineering role as opposed to a data science role?
Not really - I was always set on data science once I got into it. I used software engineering more as a backup, because given my CS background it would have been easy to get a software job if I just prepped hard for their interviews.
It’s actually harder to get a data science job out of undergrad. This is because there’s a general bias towards people with graduate degrees and people with a lot of experience. So you need to have either of both - either you need to have a lot of work experience, or you need to have a PHD.
So that’s why I built experience through doing projects, research, internships, etc.
For Data Science, there’s no real standardized process when it comes to interviewing - it varies a lot from company to company (this is in contrast to software engineering where using websites like LeetCode can get you ready for almost all jobs).
So I had to spend a lot of time prepping for each specific company I interviewed with - at every stage of the process - and this ended up taking a lot of time.
When applying to Uber, did you have projects in mind you wanted to work on? How much did you know about the company?
After my sophomore year of college, I was invited for this intern open house at Uber. That’s when I met some of the team across rides, security, and eats. I spoke to this guy on the marketplace team and another guy on the maps team, I was really interested in those teams.
What’s really cool about the marketplace team specifically is that it’s at the intersection of computer science, economics, optimization, statistics, and there’s a lot of hard & interesting problems that can be solved from an algorithmic perspective.
So after this event I attended, I knew that I wanted to be on the marketplace team at Uber. So during my senior year recruiting, I reached out to someone on the marketplace team, and they were interested in me, so that’s how I started interviewing at Uber.
What is your team responsible for and why is this work critical to Uber’s business?
I’m on the Shared Rides team (which is a part of Marketplace Dynamics). The core of building new shared rides products and features come from matching improvements or UI and experience improvements. So either tweaking these algorithms, designing & analyzing experiments, understanding how users are responding to new product features - these are all very important and central to Uber’s business.
What are some challenges (both technical and non-technical) your team faces?
The biggest challenge for our team (and I think this is true for any consumer internet product) is building something that people actually like that meets your business objectives. Because everytime you change something with the product, one metric might become worse and the other might become better.
It’s also really hard to figure out what users really want and what they really like. This involves a lot of UX research, as well as experimentation. This stuff is really challenging. Here’s another example:
So, there’s an optimization & efficiency side of Shared Rides - there’s always a tension between the two. If I make something more optimal, it might hurt the experience. If I make the experience better, we have to give some leeway on the optimization side of things. So that’s this underlying technical tension that’s always there.
On the product side, as I had already mentioned, it just comes down to building something users really want. So we have designers and UX researchers who are embedded within shared rides, as well as marketing folks, and I have to work cross functionally with these guys to problem solve on a daily basis.
You interned at Quora before Uber - can you tell me differences between both companies and how that affected your work?
So Quora was a very small company - there were only 230 people or so when I was working there (two years ago). There were fewer layers of management, it was easier to know people across the company - for example I even got the chance to speak with the CEO on a couple of occasions. There was also less bureaucracy I guess.
At Uber, since it’s a bigger company, sometimes if you want to build something you might need to get buy-in from another team, there’s more bureaucracy, there’s more layers between you and executive management.
Like at Quora, I knew the Head of Data Science very well, but at Uber I can’t imagine doing that currently (given I’ve just begun my career).
At a bigger company like Uber though, you’re working on projects that have bigger scope, bigger impact on the world, and you work with a lot more people. I’m also more specialized within my role here at Uber - at Quora I could have had more flexibility in terms of what I wanted to work on. At Uber, I’m on a very specific team, in a very specific role, working on a very specific part of the product. This has significant advantages: We’re working on specialized problems that are really challenging, and I’m surrounded by people who have been thinking deeply about these problems for a while are are super passionate about these problems. There’s some incredible learning to be had there.
Finally, in a smaller company it’s also a lot easier to hang out with your teammates - Quora for instance had organized clubs (poker, badminton etc) across the board that made it really easy to meet people in different teams. At Uber, that’s much harder to do, but you meet an equivalent amount of people within your own team, since teams are much larger at Uber.
What advice would you give to someone looking to become a Data Scientist (either a career changer or a college student)?
Data science roles are defined very differently based on the team, company, size, role you’re working on. For instance, even Uber Data Science can vary greatly across teams - for example, I work on the Shared Rides / Matching team, which is mostly Operations Research, which is a field about optimization. And I didn’t even study Operations Research in college. The important thing to understand is that different teams have different scopes. For instance, the pricing team does a lot of machine learning. Some other teams are trying to understand user experience. So having a strong base is really important, because at companies like Uber, there’s many directions you could go in.
In the Data Science industry overall, there’s broadly three tracks:

Algorithms (building models, doing ML)
Inference (understanding causality)
Analytics (building dashboards, writing SQL, reporting metrics, analyzing simple A/Bs)

Most of the Data Science jobs involve Analytics or Inference.
At Quora, they were mostly on the inference side of things. They were trying to understand product opportunities, trends in user behavior, and see if new product features were impactful.
On Uber, on my team at least, I’m more focused on building algorithms.
So in terms of advice: you need to focus on what you’re actually interested in (within the domains listed above). Of course, there’s going to be work that’s a mix of both, but knowing which topics interest you will help you map out and identify which companies you want to work for.
Everything is going to be very team and company specific, so don’t look at titles, but actually look at what the role is, talk to people on the team, and do your research.
Stats theory is also important, but on the job you’re not really going to be actively using theory too much. What really matters is understanding and gaining intuition. For example, I didn’t study a lot of Operations Research in college, but I took a bunch of Machine Learning and Algorithms classes in college which helped me build intuition for how Operations Research works, since the field is about optimization - which is what Machine Learning and Algorithms are about.
The purpose of theory is to build intuition and understand things.
Hope you guys liked the interview! If you did, feel free to check out more interviews at CareerFair.
I'm planning on interviewing more data scientists across a wide range of companies - let me know if you have any specific questions you'd like me to ask them :)
"|hey guy - had opportun interview data scientist uber share ride team . thought I 'd share , case find help : ) what & work ? My name divyansh agarw I data scientist uber san francisco . I ’ work share ride busi , work build product grow busi . some work also involv optim effici uber ’ ride share marketplac improv graph optim algorithm rider-driv match , evalu perform via experiment simul . when first becom interest data scienc ? So , I interest machin learn predict analyt go univers . I wrote colleg essay well . but I also interest softwar engin field like secur . what realli made truli interest data scienc take data 8 UC berkeley . I realli like fact could use statist extract insight data provid valu - although I alway awar , I realiz power statist could comput facilit . after , I start bunch project , internship , got involv research . when appli job , hard choos go softwar engin role oppos data scienc role ? not realli - I alway set data scienc I got . I use softwar engin backup , given CS background would easi get softwar job I prep hard interview . It ’ actual harder get data scienc job undergrad . thi ’ gener bia toward peopl graduat degre peopl lot experi . So need either - either need lot work experi , need phd . So ’ I built experi project , research , internship , etc . for data scienc , ’ real standard process come interview - vari lot compani compani ( contrast softwar engin use websit like leetcod get readi almost job ) . So I spend lot time prep specif compani I interview - everi stage process - end take lot time . when appli uber , project mind want work ? how much know compani ? after sophomor year colleg , I invit intern open hous uber . that ’ I met team across ride , secur , eat . I spoke guy marketplac team anoth guy map team , I realli interest team . what ’ realli cool marketplac team specif ’ intersect comput scienc , econom , optim , statist , ’ lot hard & interest problem solv algorithm perspect . So event I attend , I knew I want marketplac team uber . So senior year recruit , I reach someon marketplac team , interest , ’ I start interview uber . what team respons work critic uber ’ busi ? I ’ share ride team ( part marketplac dynam ) . the core build new share ride product featur come match improv UI experi improv . So either tweak algorithm , design & analyz experi , understand user respond new product featur - import central uber ’ busi . what challeng ( technic non-techn ) team face ? the biggest challeng team ( I think true consum internet product ) build someth peopl actual like meet busi object . becaus everytim chang someth product , one metric might becom wors might becom better . It ’ also realli hard figur user realli want realli like . thi involv lot UX research , well experiment . thi stuff realli challeng . here ’ anoth exampl : So , ’ optim & effici side share ride - ’ alway tension two . If I make someth optim , might hurt experi . If I make experi better , give leeway optim side thing . So ’ underli technic tension ’ alway . On product side , I alreadi mention , come build someth user realli want . So design UX research embed within share ride , well market folk , I work cross function guy problem solv daili basi . you intern quora uber - tell differ compani affect work ? So quora small compani - 230 peopl I work ( two year ago ) . there fewer layer manag , easier know peopl across compani - exampl I even got chanc speak ceo coupl occas . there also less bureaucraci I guess . At uber , sinc ’ bigger compani , sometim want build someth might need get buy-in anoth team , ’ bureaucraci , ’ layer execut manag . like quora , I knew head data scienc well , uber I ’ imagin current ( given I ’ begun career ) . At bigger compani like uber though , ’ work project bigger scope , bigger impact world , work lot peopl . I ’ also special within role uber - quora I could flexibl term I want work . At uber , I ’ specif team , specif role , work specif part product . thi signific advantag : We ’ work special problem realli challeng , I ’ surround peopl think deepli problem super passion problem . there ’ incred learn . final , smaller compani ’ also lot easier hang teammat - quora instanc organ club ( poker , badminton etc ) across board made realli easi meet peopl differ team . At uber , ’ much harder , meet equival amount peopl within team , sinc team much larger uber . what advic would give someon look becom data scientist ( either career changer colleg student ) ? data scienc role defin differ base team , compani , size , role ’ work . for instanc , even uber data scienc vari greatli across team - exampl , I work share ride / match team , mostli oper research , field optim . and I ’ even studi oper research colleg . the import thing understand differ team differ scope . for instanc , price team lot machin learn . some team tri understand user experi . So strong base realli import , compani like uber , ’ mani direct could go . In data scienc industri overal , ’ broadli three track : algorithm ( build model , ML ) infer ( understand causal ) analyt ( build dashboard , write sql , report metric , analyz simpl a/b ) most data scienc job involv analyt infer . At quora , mostli infer side thing . they tri understand product opportun , trend user behavior , see new product featur impact . On uber , team least , I ’ focus build algorithm . So term advic : need focu ’ actual interest ( within domain list ) . Of cours , ’ go work ’ mix , know topic interest help map identifi compani want work . everyth go team compani specif , ’ look titl , actual look role , talk peopl team , research . stat theori also import , job ’ realli go activ use theori much . what realli matter understand gain intuit . for exampl , I ’ studi lot oper research colleg , I took bunch machin learn algorithm class colleg help build intuit oper research work , sinc field optim - machin learn algorithm . the purpos theori build intuit understand thing . hope guy like interview ! If , feel free check interview careerfair . I 'm plan interview data scientist across wide rang compani - let know specif question 'd like ask : )
53|DiscussionIs there a website/platform where you can sell/buy datasets for ML? (self.datascience)|vasa_develop|7|6|"I was thinking if there is a supply/demand enough for such a platform (where you can buy/sell) to exist. There is a ton of demand, but are there enough people willing to supply?  
Here the data providers can be organizations, or the people generating data themselves.
"|I think supply/demand enough platform ( buy/sel ) exist . there ton demand , enough peopl will suppli ? here data provid organ , peopl gener data .
54|DiscussionHow to avoid non-technical errors and bugs ? (self.datascience)|nothingveryserious|8|1|"Dear data-scientists,
How do you guys prevent non-technical errors and bugs ?
​
I work as a data-scientist in a junior position. My typical workflow consist of the following steps :
1) the client gives us a problem 
2) think about proper methodology 
3) gather the data necessary to solve the problem 
4) apply some statistical procedures to solve the problem (generally a model) 
5) build a report to send to the client (this report must follow the company's format and standards).
One aspect where I notice I am having difficulties or improvement are in what I will call the non-technical or non-statistical aspects of the workflow above. That is suppose you gather the right data and think about the proper methodology to solve the problem, but then how can I prevent errors on the coding and reporting, for instance:
- you have the right methodology, but when you are coding the model you assign a wrong variable in the code in some step and then the results are not valid ( for instance you have x_train and x_test and you mistakenly do m = x_test / 2 instead of m = x_train / 2).
- on the reporting stage, you exported the wrong results.
These are just examples.
Then you send your report and under scrutiny from your managers or revising things to answer additional questions you find this errors. Then it looks unprofessional to say that the initial results were wrong and you will have to update it. It may not inspire much confidence in your results in the future.
It has been hard for me to find ways to improve in this aspect because these types of errors are hard to predict. When you are coding you are already doing what you think it is correct. Given the time frames we have, it is also unfeasible to double check every single line of code. Also, the problems are generally very diverse in nature, so it is not like you can just adopt an automated or semi-automated methodology that you can work upon and improve, many things you have to build from scratch every time you receive a new project.
​
How do you guys prevent this type of errors ?
​
Thanks in advance.
"|dear data-scientist , how guy prevent non-techn error bug ? ​ I work data-scientist junior posit . My typic workflow consist follow step : 1 ) client give us problem 2 ) think proper methodolog 3 ) gather data necessari solv problem 4 ) appli statist procedur solv problem ( gener model ) 5 ) build report send client ( report must follow compani 's format standard ) . one aspect I notic I difficulti improv I call non-techn non-statist aspect workflow . that suppos gather right data think proper methodolog solv problem , I prevent error code report , instanc : - right methodolog , code model assign wrong variabl code step result valid ( instanc x_train x_test mistakenli = x_test / 2 instead = x_train / 2 ) . - report stage , export wrong result . these exampl . then send report scrutini manag revis thing answer addit question find error . then look unprofession say initi result wrong updat . It may inspir much confid result futur . It hard find way improv aspect type error hard predict . when code alreadi think correct . given time frame , also unfeas doubl check everi singl line code . also , problem gener divers natur , like adopt autom semi-autom methodolog work upon improv , mani thing build scratch everi time receiv new project . ​ how guy prevent type error ? ​ thank advanc .
55|EducationDoes anybody know how to share the google colab document so people can run the notebook but cannot see the actual code? (self.datascience)|RohanJ2006|8|4|"I am trying to share the google colab document (that contains my data-visualization project) with friends so they can run the code but not actually see the code, because I don't want them to copy the code. How do I do this?
"|I tri share googl colab document ( contain data-visu project ) friend run code actual see code , I n't want copi code . how I ?
56|ToolingTableau software (self.datascience)|JaeBreezy|9|8|"Hey there, 
Anyone know of a way to get a free limited version of Tableau for personal use and self-study?
"|hey , anyon know way get free limit version tableau person use self-studi ?
57|Job SearchInterview at Amazon for Data Scientist Role -- how to prepare? (self.datascience)|bm0r3son|121|283|"I am currently a Lead Data Scientist at a large defense contractor, primarily applying data science solutions to business-facing homerooms. Think supply chain, business management, etc. 
A few highlights about me...

Very strong SQL skills, and I have done a large amount of data ETL
Moderately strong Python skills
Top 1% on Stack Overflow (I answer a lot of SQL and Python questions, also ask some)
Nearly 10 internal Trade Secrets awarded to products I have built
B.S. in Information Technology, I am graduating in August with my M.S. in Computer Science w/ an AI concentration from Hopkins
About 3.5 years of work experience out of undergrad, two internships at Defense contractors before that
Also have security related certifications (Security+)
I mentor both the cybersecurity and AI clubs for my high school (along with a few other alumni)

I was contacted on LinkedIn by a recruiter. I have never really had an intention of working at FAANG organizations. From what I have read both on Reddit and elsewhere, the ""work 7 days a week"" and high pressure culture doesn't fit what I am really looking for. However, the recruiter mentioned almost 60% more than I make now, so that was enticing.
I feel technically sound -- but I definitely don't know how succinctly I could give an answer to some technical questions. I've looked at:
https://towardsdatascience.com/the-amazon-data-scientist-interview-93ba7195e4c9 
https://towardsdatascience.com/amazon-data-scientist-interview-practice-problems-15b9b86e86c6 
https://www.reddit.com/r/datascience/comments/dn5uxq/amazon_data_scienceml_interview_questions/ 
Are these good resources? Should I be prepared to write an algorithm from scratch? Would it be easier things, like kmeans, or am I expected to code backprop from scratch? I've done these things from scratch before, but I used reference material... I am nervous about not being able to demonstrate my skills because of being too focused on providing these overly technical answers.
Any advice is appreciated!
Edit: Wow! This blew up. I certainly was not expecting this much feedback, and certainly not so much kindness. As a somewhat new graduate ( < 5 years) who is still figuring out their own self confidence, getting to share a little bit of my background and my fears moving forward with you all has been cathartic, not to mention the sheer volume of incredibly useful feedback I have gotten. I am going to think some thing through tomorrow, and I'll be sure to update this post. If I go along with the interview, which I think i will based on this feedback, ill be sure to create an update post to let you all know what happened!
"|I current lead data scientist larg defens contractor , primarili appli data scienc solut business-fac homeroom . think suppli chain , busi manag , etc . A highlight ... veri strong sql skill , I done larg amount data etl moder strong python skill top 1 % stack overflow ( I answer lot sql python question , also ask ) nearli 10 intern trade secret award product I built b. . inform technolog , I graduat august m. . comput scienc w/ AI concentr hopkin about 3.5 year work experi undergrad , two internship defens contractor also secur relat certif ( security+ ) I mentor cybersecur AI club high school ( along alumni ) I contact linkedin recruit . I never realli intent work faang organ . from I read reddit elsewher , `` work 7 day week '' high pressur cultur n't fit I realli look . howev , recruit mention almost 60 % I make , entic . I feel technic sound -- I definit n't know succinctli I could give answer technic question . I 've look : http : //towardsdatascience.com/the-amazon-data-scientist-interview-93ba7195e4c9 http : //towardsdatascience.com/amazon-data-scientist-interview-practice-problems-15b9b86e86c6 http : //www.reddit.com/r/datascience/comments/dn5uxq/amazon_data_scienceml_interview_questions/ are good resourc ? should I prepar write algorithm scratch ? would easier thing , like kmean , I expect code backprop scratch ? I 've done thing scratch , I use refer materi ... I nervou abl demonstr skill focus provid overli technic answer . ani advic appreci ! edit : wow ! thi blew . I certainli expect much feedback , certainli much kind . As somewhat new graduat ( < 5 year ) still figur self confid , get share littl bit background fear move forward cathart , mention sheer volum incred use feedback I gotten . I go think thing tomorrow , I 'll sure updat post . If I go along interview , I think base feedback , ill sure creat updat post let know happen !
58|ProjectsWhat would be some good datasets to explore for identifying systemic/institutionalized racism? (self.datascience)|sjksjksjk|5|0|"This post is not meant to be a statement of political belief or discussion about current events, necessarily. That being said, current events have led me to wonder: what can the data science community do to identify instances of systemic racial bias? What if you could apply the spirit of a fault detection model to a sociological/demographic/economic-related dataset?
Anyone aware of any datasets (or even bounds for what would constitute a useful dataset) with this goal in mind?
I'm not asserting that you can just throw code, models, and data at a deeply rooted social issue and expect it to magically resolve - just that maybe there are some opportunities here.
"|thi post meant statement polit belief discuss current event , necessarili . that said , current event led wonder : data scienc commun identifi instanc system racial bia ? what could appli spirit fault detect model sociological/demographic/economic-rel dataset ? anyon awar dataset ( even bound would constitut use dataset ) goal mind ? I 'm assert throw code , model , data deepli root social issu expect magic resolv - mayb opportun .
59|DiscussionWhat are good resources to learn about AWS project scoping and management? (self.datascience)|Stewthulhu|0|3|"There are a huge number of options and architectures available for AWS. Although the individual instance types and services are described well by the AWS informational resources, I'm having a hard time finding good resources on how to actually combine them to build a reliable and cost-effective infrastructure for a given project. Are there any good resources for learning about AWS project scoping and project management?
"|there huge number option architectur avail aw . although individu instanc type servic describ well aw inform resourc , I 'm hard time find good resourc actual combin build reliabl cost-effect infrastructur given project . are good resourc learn aw project scope project manag ?
60|EducationWhat Stats/IT journals or magazines do you regularly read? (self.datascience)|malasi|5|4|"Full disclosure: I used to like Medium, but nowadays I think not all of their content is necessarily very high quality (or maybe it's just me who matured in the past two years). I'd love to find something similar like Nature is in the natural sciences, although I realize DS is probably too small of a field at the moment to produce a comparably popular and high quality journal.
"|full disclosur : I use like medium , nowaday I think content necessarili high qualiti ( mayb 's matur past two year ) . I 'd love find someth similar like natur natur scienc , although I realiz DS probabl small field moment produc compar popular high qualiti journal .
61|DiscussionIndustry working professionals: What do you use to maintain different versions of models ? (self.datascience)|kkziga|9|7|"I am working on a certain prediction based project. I now have 3-4 models and around 2-3 varients of each models (different hyperparameters, minor changes in architecture etc). Currently I am making a seperate folder for each model, sub folder for each of it's variant and maintaining a report (basically a summary table) of accuracy of models and other meta details. I realised that this approach is not scalable. What system/approach do you use to tackle this and reduce your stress in maintaining model versions ?
"|I work certain predict base project . I 3-4 model around 2-3 varient model ( differ hyperparamet , minor chang architectur etc ) . current I make seper folder model , sub folder 's variant maintain report ( basic summari tabl ) accuraci model meta detail . I realis approach scalabl . what system/approach use tackl reduc stress maintain model version ?
62|DiscussionWho are you? (self.datascience)|RyBread7|8|2|"I'm really interested in getting an idea of who is a part of this community and where they are right now.
View Poll
"|I 'm realli interest get idea part commun right . view poll
63|DiscussionWhat do you look for/wish to see in a public data set? (self.datascience)|JayWalkerC|0|1|"I'm putting together a data set of ~100k randomly played games of a two-player board game. The games are stored as JSON files with each board state and the turns that were made throughout, as well as which player won the game. 
So far I've split the files in to two folders (one for wins by the first player, other folder for wins by the second player), and written a README.md describing the structure of the JSON files and info on how the games were generated.
What are some things you would wish to see included in a data set like this that I might be overlooking?
"|I 'm put togeth data set ~100k randomli play game two-play board game . the game store json file board state turn made throughout , well player game . So far I 've split file two folder ( one win first player , folder win second player ) , written readme.md describ structur json file info game gener . what thing would wish see includ data set like I might overlook ?
64|MetaAny data science centered Slack workspaces in English you recommend? (self.datascience)|Optimesh|0|0|empty|empti
65|DiscussionHow DS has helped you with your career? (self.datascience)|runnersgo|0|1|"This is more to the folks that are not necessarily in a DS role, but do DS in their day-to-day tasks; care to share experiences, stories or even anecdotes seeing how DS helped you with your career?
For me, I was interested in Game theory (and wanted to be a bit more ""politically"" involved in the company that I was working with e.g. showing my ability to be more precise in my articulation, and get upper management approvals); I developed a somewhat simple descriptive model, a small dashboard and analytics during a critical phase of the company and did a presentation; to this day I was known to be ""unique"" in my abilities to articulate facts, which got the attention of my higher ups!
How about you guys?
"|thi folk necessarili DS role , DS day-to-day task ; care share experi , stori even anecdot see DS help career ? for , I interest game theori ( want bit `` polit '' involv compani I work e.g . show abil precis articul , get upper manag approv ) ; I develop somewhat simpl descript model , small dashboard analyt critic phase compani present ; day I known `` uniqu '' abil articul fact , got attent higher up ! how guy ?
66|DiscussionData management books for data scientists? (self.datascience)|stigmatic666|18|149|"Interested in learning more about the whole data ecosystem and wondering if anyone has book recommendations on: data warehousing, data engineering & data management.
"|interest learn whole data ecosystem wonder anyon book recommend : data wareh , data engin & data manag .
67|DiscussionThemes/Templates for plotly dash (self.datascience)|aryancodify|1|2|"I have to build a dashboard for one of my work projects. I have choosen dash as my choice. I was wondering if there are any themes/templates that I can use as the base and build on top of it. THe main reason is that I am not that good with CSS and this can help me design something that has good look and feel.
"|I build dashboard one work project . I choosen dash choic . I wonder themes/templ I use base build top . the main reason I good css help design someth good look feel .
68|ProjectsClustering analysis for curves? (self.datascience)|30minute_un|22|3|"Working on a project where I'm doing some curve fitting. Wondering if there's an easy way to group many separate results based on similarity? Either on a visual plotting of the curves themselves or on the underlying values (list of 100 numbers). Working in python but also know R if that's a better fit for this task.
"|work project I 'm curv fit . wonder 's easi way group mani separ result base similar ? either visual plot curv underli valu ( list 100 number ) . work python also know R 's better fit task .
69|DiscussionFuture of Data science? (self.datascience)|Rocktrees|10|3|"I've been reading about what the future will hold for Data science, and some of the stuff is bleak. I keep hearing that AI will replace the need for real data science work and that data engineers are more important. I wanted to see what you guys think.
"|I 've read futur hold data scienc , stuff bleak . I keep hear AI replac need real data scienc work data engin import . I want see guy think .
70|Job SearchHow do you answer behavioral based tech questions if you work in a calm job environment? (self.datascience)|dt25to|14|6|"I feel my situation is a little unique. Work as the only data scientist for my company and pretty much any recommendation I put forward goes through without any push back from management. There are no conflicts etc as I'm the only data scientist and my manager is really chill so no tight deadlines and issues with management either.
My issue is that now that I'm looking to move to another company, the interviews require you to answer behavioral questions but with a technical aspect to it. I just don't know how to answer conflict or deadline or last minute change questions in a technical manner because I've never faced such situations at my current job. I don't know if i would be answering incorrectly in an over simplistic manner would be too simple of an example for the tech recruiter.
At this point i sort of have to come up with fake scenarios around my work to make it seem like there were conflicts and tight deadlines
Does anyone have any suggestions on how to frame my answers or create such scenarios that seem behavioral based but also technically challenging. Like what exactly do I talk about.. pvalues?? Feature selection?
"|I feel situat littl uniqu . work data scientist compani pretti much recommend I put forward goe without push back manag . there conflict etc I 'm data scientist manag realli chill tight deadlin issu manag either . My issu I 'm look move anoth compani , interview requir answer behavior question technic aspect . I n't know answer conflict deadlin last minut chang question technic manner I 've never face situat current job . I n't know would answer incorrectli simplist manner would simpl exampl tech recruit . At point sort come fake scenario around work make seem like conflict tight deadlin doe anyon suggest frame answer creat scenario seem behavior base also technic challeng . like exactli I talk about.. pvalu ? ? featur select ?
71|CareerHow fast paced is data science work? (self.datascience)|Greenface1998|39|110|"Doing a data science boot camp thing rn ( before graduate school) and I’m finding the pace a bit fast. Kinda normal for a boot camp to be fast paced but it makes me wonder if  the actual work actually go at this pace. I like having room to breathe and lots and lots of time to really mull over a difficult problem, like an academic might have. I always enjoyed that aspect of university. Does your  average data scientist get that kinda time to devote to just thinking.
"|do data scienc boot camp thing rn ( graduat school ) I ’ find pace bit fast . kinda normal boot camp fast pace make wonder actual work actual go pace . I like room breath lot lot time realli mull difficult problem , like academ might . I alway enjoy aspect univers . doe averag data scientist get kinda time devot think .
72|DiscussionEDA revisited (self.datascience)|kreuzguy|3|0|"As we know, EDA (Exploratory Data Analysis) is a very common procedure in the field. We use it mainly to find inconsistencies in the data, to uncover simple patterns that could alter our perceptions of what we are dealing with and to build insightful visualizations. I think we can all agree how this type of information can be critical. What I would like to do here, and I hope you bear with me, is to question what seems to me a overly optimistic application of this technique.
So, a little context. I've been working on a small consultant startup that leverage data science techniques to serve our costumers. As you can probably guess, most of our services involve helping our clients make sense of their data and extract useful information that can maximize their profits. 
In the project I'm in, for 3 months we have been doing EDA and communicating our results through Power Point presentations. Although sometimes we could find something that was potentially interesting, this experience left me questioning the value of EDA when applied in isolation. 
To explicit my argument, let's go through an example: suppose I have a database with 20 variables and my goal is to find ""something interesting"". What we usually do is trying to find correlations between these variables (be it in form of graphs of statistical tests). Suppose that I find a positive correlation between X and Y, though. What is this really saying to me? How is this accounting for confounding variables and how much variance is it capturing? My bosses don't seem to me very concerned with these questions and usually think the finding of a correlation is already an insightful thing to communicate. 
I have been trying to argument with them that no analysis could be detached from previsibility. If this variable is correlated with the outcome, but it isn't helping to predict it, then why are we so focused on it? My concerns are usually met with the same answers: ""it is important to visualize what is happening"", ""we are still exploring our data"". 
This makes me think that my approach (predictability in the first place) is kind of unusual in the field? It appears to me that EDA has became a branch of data science that is not connecting very well with everything and is becoming embedded in some other kind of rules? 
I would love to hear your opinions about it.
"|As know , eda ( exploratori data analysi ) common procedur field . We use mainli find inconsist data , uncov simpl pattern could alter percept deal build insight visual . I think agre type inform critic . what I would like , I hope bear , question seem overli optimist applic techniqu . So , littl context . I 've work small consult startup leverag data scienc techniqu serv costum . As probabl guess , servic involv help client make sens data extract use inform maxim profit . In project I 'm , 3 month eda commun result power point present . although sometim could find someth potenti interest , experi left question valu eda appli isol . To explicit argument , let 's go exampl : suppos I databas 20 variabl goal find `` someth interest '' . what usual tri find correl variabl ( form graph statist test ) . suppos I find posit correl X Y , though . what realli say ? how account confound variabl much varianc captur ? My boss n't seem concern question usual think find correl alreadi insight thing commun . I tri argument analysi could detach previs . If variabl correl outcom , n't help predict , focus ? My concern usual met answer : `` import visual happen '' , `` still explor data '' . thi make think approach ( predict first place ) kind unusu field ? It appear eda becam branch data scienc connect well everyth becom embed kind rule ? I would love hear opinion .
73|DiscussionWell today was a depressing day for data science at work. What can I do better? (self.datascience)|dontlookmeupplease|272|381|"I work as an Analytics Manager and normally I don't really share with my colleagues the in depth details of my work because nobody is technical. They just know I use SQL and Python to spit out a report and that's all they really understand.
Recently I had an opportunity to do something interesting where I had a very skewed data set and was asked to make sense of it. I thought applying a log transformation to normalize the data as the distribution was extremely skewed and thought it would make the data easier to interpret and I was happy with the results.
My colleagues wanted to know how I arrived at my conclusion for my recommendation so I walked them through the process. I provided a high level overview, but they really wanted to get into the nitty gritty of exactly HOW I got to where I got. Again, I normally don't like to do this because they tend ask very detailed questions like ""Can you explain exactly how this works so I can understand?"" and it gets tough to explain certain things (e.g., I would say something like ""I got this raw data from the API"" but then it's followed up by a question like ""What is an API and why didn't you just use the vendor's dashboard? Why doesn't the vendor's interface provide the data? Why do you have to go through this step?"").
Well anyway I was explaining my logic and really tip toed around the stats by really trying to say essentially that I applied some logic that would more even distribute the data. I stupidly said the word ""log"" and it was over. Their faces froze for a good 10 seconds before someone spoke.
""I'm sorry..but what? What is log? Why do you need this log? I'm really confused. How am I suppose to explain this to the SVP? Can you just change it so you're indexing off the median or mean? This doesn't make any sense.""
I'm dead.
So guys, how do you avoid getting away with having to explain things by  not using technical jargon? I mean like I said, I normally just show people the output of my report and I don't get too many in depth questions about it, but when people really pry, it gets tough. I don't know how to avoid saying ""I ran a regression model"" because it freaks people out and they get upset because they don't understand it and want me to do something that is easier to interpret. It's already frustrating that they think I'm over complicating things by using Python instead of Excel, but I can at least tell them certain things like Excel can't handle 1+ million rows and they can understand that.
EDIT: Hey all, appreciate all you feedback, both positive and negative. I think it's all constructive. There's a lot of replies in this thread so it's hard to answer everyone's questions. Some of you ask the same things and I do answer them, but you might have to dig through the comments to find it. In any case, let me post some frequently asked ones:
1) Did you use graphs and visuals?
Answer: I did. I actually stayed away from using the word log at first and just showed them a histogram of what the data looked like before the log transform and then after the log transform. What followed up was ""How did you do this? What did you use to index the numbers?"" And that's when I mentioned I used a log transformation.
2) How did you explain what a log transform was?
Answer: I didn't directly explain it in math terms. I described it in the form of an analogy or comparable example. This is what I said: 
""Imagine we were looking at salaries for a company. Most people for example will make a salary between something like $40 - 100k right? Well what if the top execs in the company make like $10 million dollars. Now imagine you tried to index using the mean? Wouldn't the mean say the average employee at this company makes a salary of $1 million dollars or something? That's not right. Basically, a log transformation would keep everyone's differences in consideration, but minimize the importance of some of those execs who are not entirely representative of the rest of the company. That way you can better see the difference in salary among every worker and not have your vision obscured by some of these execs who are throwing off that balance. ""
Unfortunately, this proved to be even more confusing and my colleagues really zoned in on exactly what a log was and how it's calculated and it was tough to navigate from there.
3) What is SVP?
Answer: It stands for Senior Vice President. It basically is a reference to our execs.
"|I work analyt manag normal I n't realli share colleagu depth detail work nobodi technic . they know I use sql python spit report 's realli understand . recent I opportun someth interest I skew data set ask make sens . I thought appli log transform normal data distribut extrem skew thought would make data easier interpret I happi result . My colleagu want know I arriv conclus recommend I walk process . I provid high level overview , realli want get nitti gritti exactli how I got I got . again , I normal n't like tend ask detail question like `` can explain exactli work I understand ? '' get tough explain certain thing ( e.g. , I would say someth like `` I got raw data api '' 's follow question like `` what api n't use vendor 's dashboard ? whi n't vendor 's interfac provid data ? whi go step ? '' ) . well anyway I explain logic realli tip to around stat realli tri say essenti I appli logic would even distribut data . I stupidli said word `` log '' . their face froze good 10 second someon spoke . `` I 'm sorry..but ? what log ? whi need log ? I 'm realli confus . how I suppos explain svp ? can chang 're index median mean ? thi n't make sens . '' I 'm dead . So guy , avoid get away explain thing use technic jargon ? I mean like I said , I normal show peopl output report I n't get mani depth question , peopl realli pri , get tough . I n't know avoid say `` I ran regress model '' freak peopl get upset n't understand want someth easier interpret . It 's alreadi frustrat think I 'm complic thing use python instead excel , I least tell certain thing like excel ca n't handl 1+ million row understand . edit : hey , appreci feedback , posit neg . I think 's construct . there 's lot repli thread 's hard answer everyon 's question . some ask thing I answer , might dig comment find . In case , let post frequent ask one : 1 ) did use graph visual ? answer : I . I actual stay away use word log first show histogram data look like log transform log transform . what follow `` how ? what use index number ? '' and 's I mention I use log transform . 2 ) how explain log transform ? answer : I n't directli explain math term . I describ form analog compar exampl . thi I said : '' imagin look salari compani . most peopl exampl make salari someth like $ 40 - 100k right ? well top exec compani make like $ 10 million dollar . now imagin tri index use mean ? would n't mean say averag employe compani make salari $ 1 million dollar someth ? that 's right . basic , log transform would keep everyon 's differ consider , minim import exec entir repres rest compani . that way better see differ salari among everi worker vision obscur exec throw balance. `` unfortun , prove even confus colleagu realli zone exactli log 's calcul tough navig . 3 ) what svp ? answer : It stand senior vice presid . It basic refer exec .
74|DiscussionK-Means vs vector quantization (self.datascience)|warlax56|2|4|"Howdy,
So, everyone knows about K-Means as a form of general clustering algorithm. Vector quantization is similarly centroid based, but rather uses a feed forward network to generate that Veroni styled segregation pattern via a (for lack of a better phrase) loser takes all output.
Is there any significant difference in these two algorithms? They seem like they would both have similar results; they both use random starting states, and rely on small adjustments potentially locking them in local minima. It seems like the only real difference is that k means is simpler, more efficient, and more direct.
"|howdi , So , everyon know k-mean form gener cluster algorithm . vector quantiz similarli centroid base , rather use feed forward network gener veroni style segreg pattern via ( lack better phrase ) loser take output . Is signific differ two algorithm ? they seem like would similar result ; use random start state , reli small adjust potenti lock local minima . It seem like real differ k mean simpler , effici , direct .
75|DiscussionWorst example of data stupidity you have seen? (self.datascience)|BaikAussie|78|103|"It's Friday, lets vent!
Will share my story but heavily changed to protect the guilty.  
I work(ed) in a safety field where people die based on decisions. We risk rate things, and use our limited resources to prioritise what we need to fix. For arguments sake, I have put this in the context of safety of vehicles.
Someone in another department came up with a subjective but otherwise understandable way of risk rating. Things  like 

if there are seatbelts, subtract 1
add the number of accidents in the last year
if there is speed monitoring, subtract 1
if no licence is required, add 2
subtract 1 for every time they have been inspected

As you can see, some of these were real numbers, some ordinal, some categorical and so on.
These numbers are added to give a final ""risk"" score for a vehicle. So far, so dodgy.
However, this total ""number"" was then ranked, and then multiplied by the number of passengers to give an overall value, which was then multiplied by the amount of safety dollars we had to spend to work out what we should do.
Needless to say, my mood quickly went from appalled to ""holy shit we need to never let anyone outside the organisation see how we do this...""
"|It 's friday , let vent ! will share stori heavili chang protect guilti . I work ( ed ) safeti field peopl die base decis . We risk rate thing , use limit resourc prioritis need fix . for argument sake , I put context safeti vehicl . someon anoth depart came subject otherwis understand way risk rate . thing like seatbelt , subtract 1 add number accid last year speed monitor , subtract 1 licenc requir , add 2 subtract 1 everi time inspect As see , real number , ordin , categor . these number ad give final `` risk '' score vehicl . So far , dodgi . howev , total `` number '' rank , multipli number passeng give overal valu , multipli amount safeti dollar spend work . needless say , mood quickli went appal `` holi shit need never let anyon outsid organis see ... ''
76|ToolingAnyone use their home rigs for work? (self.datascience)|Kassme|4|1|"Just built a PC that blows my work computer out of the water in terms of computing power and speed, and it got me thinking about how much more productive I could be if I was able to run some of my heavier scripts/tools from work on it. My company has pretty tight InfoSec, but I do have a soft token for VPN on my personal phone, so I do know they do allow personal devices to be used in that capacity. 
I'm curious if anyone out there has done something like this before? Or maybe the takeaway is I should just request a more powerful work computer.
Thanks!
"|just built PC blow work comput water term comput power speed , got think much product I could I abl run heavier scripts/tool work . My compani pretti tight infosec , I soft token vpn person phone , I know allow person devic use capac . I 'm curiou anyon done someth like ? Or mayb takeaway I request power work comput . thank !
77|EducationData scientist going back to school for CS (self.datascience)|azzipog|23|48|"I have been a data scientist / data engineer for about 2 years with only a BA in Economics. I have always wanted to learn more on the CS side and recently decided to take night classes at the local community college. I start my first class (Programming fundamentals I) which will be taught using C++. I am pretty proficient in R and Python for modeling and ETL, but I don't have any experience with lower level languages. 
I'm super excited, and I want to know if anyone has any advice about what to focus on in my class? 
Will C++ be useful as a data scientist/engineer?
I plan on taking Programmin fundamentals II and III next. They are offered in C++ or Java. Should I pick one over the other?
My ultimate goal is to get into Georgia Tech's OMSCS program while at the same time learning valuable skills for my job
"|I data scientist / data engin 2 year BA econom . I alway want learn CS side recent decid take night class local commun colleg . I start first class ( program fundament I ) taught use c++ . I pretti profici R python model etl , I n't experi lower level languag . I 'm super excit , I want know anyon advic focu class ? will c++ use data scientist/engin ? I plan take programmin fundament II iii next . they offer c++ java . should I pick one ? My ultim goal get georgia tech 's omsc program time learn valuabl skill job
78|DiscussionI know it’s a weird question but, What do you think it would be like to be a data scientist at pornhub? (self.datascience)|a_wsty|168|401|"I’ve seen some of the visualizations showing different viewing patterns by state and it makes me wonder
- What’s working there like
- How’s the pay (I could see it either being really good or really bad
- how rich is their dataset
As one of the most viewed sites on the internet they must have some data science types working there
"|I ’ seen visual show differ view pattern state make wonder - what ’ work like - how ’ pay ( I could see either realli good realli bad - rich dataset As one view site internet must data scienc type work
79|DiscussionHow easy or hard is to deploy Dash dashboard on a custom server? (self.datascience)|vasili111|6|4|"I am exploring Dash at the moment a and finding it very interesting.
My question is: How easy or hard is to deploy Dash on custom Linux server?
"|I explor dash moment find interest . My question : how easi hard deploy dash custom linux server ?
80|DiscussionJust sitting around, waiting for my data to load... (self.datascience)|r0ck13r4c00n|6|1|"What’s your favorite ETL tool?
"|what ’ favorit etl tool ?
81|DiscussionConvention on Multiple Imputation for ML models? (self.datascience)|___word___|6|4|"Hi guys, I'm trying to build a binary outcome classifier for a dataset and I'm kind of stumped by a particular feature in the data which have ~20% of its values missing in both the training and testing sets. This feature has about a r=0.077 correlation with the outcome (measured from observed data in the training set).
I'm looking to do Multiple Imputation on the missing values and I gather that I basically need to do the following:

Choose a single imputation method with a random component (regression with random error term, regression with bootstrap samples, etc.), impute missing values x times to get x separate datasets
Do my analysis (build an ML model) x times to get x different sets of results (model parameters)
Average the results to get 1 set of model parameters

I was wondering if it would be okay if I just did step 1 and averaged the missing values into 1 complete dataset? I ask because this seems like it may not be worth the hassle for something with only a r=0.077 with the outcome, and coupled with missing values in other features I would end up with a lot of models if I chose this approach. Is there a better way to do this? Also how would this approach work from a testing point of view? Would I just impute multiple testing sets and take a majority vote of the predictions?
"|Hi guy , I 'm tri build binari outcom classifi dataset I 'm kind stump particular featur data ~20 % valu miss train test set . thi featur r=0.077 correl outcom ( measur observ data train set ) . I 'm look multipl imput miss valu I gather I basic need follow : choos singl imput method random compon ( regress random error term , regress bootstrap sampl , etc . ) , imput miss valu x time get x separ dataset Do analysi ( build ML model ) x time get x differ set result ( model paramet ) averag result get 1 set model paramet I wonder would okay I step 1 averag miss valu 1 complet dataset ? I ask seem like may worth hassl someth r=0.077 outcom , coupl miss valu featur I would end lot model I chose approach . Is better way ? also would approach work test point view ? would I imput multipl test set take major vote predict ?
82|ToolingMulesoft vs rhapsody (self.datascience)|datajen|1|1|"Hi!
I’m on a project team, aimed at determining best integration and API platforms. We’ve spoken a lot about DataStage (internally), but less about Rhapsody and mulesoft. 
Can anyone share a brief pro/con of the two? Or maybe when you would choose one over the other (other than cost and worker capacity)?
"|Hi ! I ’ project team , aim determin best integr api platform . We ’ spoken lot datastag ( intern ) , less rhapsodi mulesoft . can anyon share brief pro/con two ? Or mayb would choos one ( cost worker capac ) ?
83|Cloud permissions for Data Scientists - anyone happy with their company's setup? (self.datascience)|dfphd|48|77|"A recurring issue I've had to deal with in my career has been IT governance and the ability of myself (or my teams) to be able to use or test out cloud functionality independently (i.e., not needing IT to set everything up for my first).
For those in companies with tight permission policies:

How is your access to cloud resources set up?


Are you able to spin up compute resources by yourself (e.g., EC2)?
Are you able to connect these compute resources to production DBs, or are you only able to create these in dev environments/connect to test/backup DBs?

Are you happy with it?

EDIT for clarification:

I am not advocating against IT governance - I think it certainly has a purpose and just giving users ""God privileges"" as u/lacompacida so eloquently referred to is not the answer. What I am interested in is how others (companies) are managing the tradeoff between cybersecurity risks and data scientist's autonomy.
For example, I think u/SlightBerry brings up what seems like a valid stance - users should be able to deploy resources as needed, and security should be handled not by overseeing what users are spinning up, but by making sure that whatever they spin up is isolated enough not to generate issues. I certainly have questions regarding that setup, but clearly there is a balance between giving any joe shmoe complete access to prod vs. requiring even your most senior DS to open a ticket to get a compute instance stood up.

"|A recur issu I 've deal career IT govern abil ( team ) abl use test cloud function independ ( i.e. , need IT set everyth first ) . for compani tight permiss polici : how access cloud resourc set ? are abl spin comput resourc ( e.g. , ec2 ) ? are abl connect comput resourc product db , abl creat dev environments/connect test/backup db ? are happi ? edit clarif : I advoc IT govern - I think certainli purpos give user `` god privileg '' u/lacompacida eloqu refer answer . what I interest other ( compani ) manag tradeoff cybersecur risk data scientist 's autonomi . for exampl , I think u/slightberri bring seem like valid stanc - user abl deploy resourc need , secur handl overse user spin , make sure whatev spin isol enough gener issu . I certainli question regard setup , clearli balanc give joe shmoe complet access prod vs. requir even senior DS open ticket get comput instanc stood .
84|Masters Degree or Old Stressful Job (self.datascience)|sizzlepoop|54|32|"Hello all, I got laid off from a Data Quality Assurance job due to covid at the beginning of April, and I was accepted into an applied data science masters program at USC (University of Southern California) during this time off. The pay was good at the job, but I was extremely stressed out and didn’t receive overtime on days I would work extra. I was only there for 3 months, and now they’re asking me to come back. Do you think I should pursue a masters (2 year program) at $70K tuition or accept the offer again which pays 75k?
Background: I graduated in January of 2019 and have about 1.5 years of data ANALYST experience under my belt so far.
Thanks in advance!
Edit: I should also note that this is without FAFSA considered as I haven’t received notice yet. 
I have experience in Power BI, SQL, Python, and Excel which are all fine for data analyst roles, but my question would be is experience enough to get me from an analyst position to a scientist position?
The USC program focuses on Machine Learning and Webscraping, as well as Hadoop/MapReduce/Spark. 
I have a bachelors in Business Analytics if that matters.
Appreciate the input from everyone so far as well
"|hello , I got laid data qualiti assur job due covid begin april , I accept appli data scienc master program usc ( univers southern california ) time . the pay good job , I extrem stress ’ receiv overtim day I would work extra . I 3 month , ’ ask come back . Do think I pursu master ( 2 year program ) $ 70k tuition accept offer pay 75k ? background : I graduat januari 2019 1.5 year data analyst experi belt far . thank advanc ! edit : I also note without fafsa consid I ’ receiv notic yet . I experi power BI , sql , python , excel fine data analyst role , question would experi enough get analyst posit scientist posit ? the usc program focus machin learn webscrap , well hadoop/mapreduce/spark . I bachelor busi analyt matter . appreci input everyon far well
85|DiscussionAlternative approaches to ARIMA for Time Series prediction (No Neural Networks) (self.datascience)|cmprogrammers|28|31|"Hi everyone,
I have data on three years of weekly sales for a market, plus some information about brands, promos etc . Researching about Time Series analysis, I came about ARIMA and SAIRMA models, which seems to be the standard approach for this type of data analysis and forecast.
I was wondering, is it ARIMA also the only or best option? Is it possible to use also some other algorithms that may turn out to be more effective? If so, what would you suggest?
Thank you
"|Hi everyon , I data three year weekli sale market , plu inform brand , promo etc . research time seri analysi , I came arima sairma model , seem standard approach type data analysi forecast . I wonder , arima also best option ? Is possibl use also algorithm may turn effect ? If , would suggest ? thank
86|EducationDeploy Machine Learning Pipeline on Google Kubernetes Engine (self.datascience)|moezali|1|0|"Are you a data scientist and you haven't deployed machine learning model yet  .... then this one is for you ☟  
Our latest medium post is a step-by-step beginner’s guide to containerize and deploy machine learning pipeline on Google Kubernetes Engine.  
If you have never heard about containerization, docker and Kubernetes before, no problem - this is what this tutorial is all about. In this tutorial you will learn:  
✔ What is a Container, What is Docker, What is Kubernetes, and What is Google Kubernetes Engine? 
✔ Build a Docker image and upload it on Google Container Registry (GCR). 
✔ Create clusters and deploy a machine learning pipeline with Flask app as a web service. 
✔ See a web app in action that uses a trained machine learning pipeline to predict on new data points in real-time. 
https://medium.com/@moez_62905/deploy-machine-learning-model-on-google-kubernetes-engine-94daac85108b
"|are data scientist n't deploy machin learn model yet ... . one ☟ our latest medium post step-by-step beginn ’ guid container deploy machin learn pipelin googl kubernet engin . If never heard container , docker kubernet , problem - tutori . In tutori learn : ✔ what contain , what docker , what kubernet , what googl kubernet engin ? ✔ build docker imag upload googl contain registri ( gcr ) . ✔ creat cluster deploy machin learn pipelin flask app web servic . ✔ see web app action use train machin learn pipelin predict new data point real-tim . http : //medium.com/ @ moez_62905/deploy-machine-learning-model-on-google-kubernetes-engine-94daac85108b
87|DiscussionHow do you keep your useful / reusable codes? (self.datascience)|barata_de_gravata|4|2|"I am creating a ""tool box"" that is pretty much a big google colab file with useful codes, this way my basic projects would be more modulated and easily implanted, but not sure if i am doing it the best way, so thought you guys may be doing something like this.
"|I creat `` tool box '' pretti much big googl colab file use code , way basic project would modul easili implant , sure best way , thought guy may someth like .
88|DiscussionHow deep is your statistics knowledge? (self.datascience)|CacheMeUp|122|269|"I work a lot with ""heavy"" statisticians (mostly bio-statisticians). They typically get involve after we do all the data engineering and NLP part. Their knowledge of stats of course overshadows that of my team, which brings me to the question - what is the value of a data scientist without such knowledge?
It's true that we do all the heavy work, but the statisticians are the ones making the calls about the study design, scrutinize the results etc. 
It makes my teammate feel like low-skilled workers in the whole process, and they fear that they will be easily replaceable. 
What do you think?
"|I work lot `` heavi '' statistician ( mostli bio-statistician ) . they typic get involv data engin nlp part . their knowledg stat cours overshadow team , bring question - valu data scientist without knowledg ? It 's true heavi work , statistician one make call studi design , scrutin result etc . It make teammat feel like low-skil worker whole process , fear easili replac . what think ?
89|EducationCookiecutter projects (self.datascience)|idkwhattoxhuz|6|5|"I am trying to develop my first DS project using cookiecutter but I am having hard time understanding its bits and pieces.
If anyone knows or have developed any actual DS projects developed using it or any other template, please share links. it will be easier to understand the whole process. Thank you
"|I tri develop first DS project use cookiecutt I hard time understand bit piec . If anyon know develop actual DS project develop use templat , pleas share link . easier understand whole process . thank
90|DiscussionHave you found PLS regression useful? (self.datascience)|RyBread7|7|1|"Conceptually, it seems to me that partial least squares regression should be excellent in some situations. However, ISLR states ""...it often performs no better than ridge regression or PCR (principle component regression)"" and that ""...the overall benefit of PLS relative to PCR is a wash"". Applied Predictive Modelling, on the other hand, describes PLS in a much more positive light. I was hoping someone might be able to speak from experience as to whether they have found PLS to significantly outperform other methods or not.
"|conceptu , seem partial least squar regress excel situat . howev , islr state `` ... often perform better ridg regress pcr ( principl compon regress ) '' `` ... overal benefit pl rel pcr wash '' . appli predict model , hand , describ pl much posit light . I hope someon might abl speak experi whether found pl significantli outperform method .
91|DiscussionHow to deal with images with text noise? (self.datascience)|SuccessfulLeadership|1|2|"I have a dataset of images collected from google and bing images (scraped). basically I want to classify these images into binary classes (positive, negative). Images that contain a text originally from the image (a photo of contract) should be classified positive (there are some other cases where the image also should be positive but my problem is with the textual images). I'm facing a problem that many negative images have text and caption that's add on the photo like a website address or logo (not original from the image). I'm afraid these images could hurt the model performance, in this case, what should I do? It doesn't make sense to through away useful images because of tiny text added on them. And could that actually hurt the model or the model would be able to capture the actual pattern from the dataset?
Thanks
"|I dataset imag collect googl bing imag ( scrape ) . basic I want classifi imag binari class ( posit , neg ) . imag contain text origin imag ( photo contract ) classifi posit ( case imag also posit problem textual imag ) . I 'm face problem mani neg imag text caption 's add photo like websit address logo ( origin imag ) . I 'm afraid imag could hurt model perform , case , I ? It n't make sens away use imag tini text ad . and could actual hurt model model would abl captur actual pattern dataset ? thank
92|ToolingPython library to make data visualization less autistic (self.datascience)|autistic_alpha|14|0|"I've used matlab but now I mainly use python 3. Matlabs plotting is complete utter garbage and I will never understand the logic behind it, I hate it with all my heart. Matplotlib in python 3 is a little bit better, but it still seems unnecessarily confusing, despite changing tick label sizes hundreds of times I always have to google it.
Is there a simple python library that can handle all the common charts patterns, outputting them aesthetically with selectable color schemes and font sizes that are fucking readable by default?
"|I 've use matlab I mainli use python 3 . matlab plot complet utter garbag I never understand logic behind , I hate heart . matplotlib python 3 littl bit better , still seem unnecessarili confus , despit chang tick label size hundr time I alway googl . Is simpl python librari handl common chart pattern , output aesthet select color scheme font size fuck readabl default ?
93|DiscussionHow do you approach game balancing as a data scientist? (self.datascience)|saintshing|5|7|"Data scientists who play competitive video games(e.g. moba, autochess, hearthstone), how would you model the problem of game balancing? Most stat websites(hsreplay.net, op.gg, etc) focus on winrates only. How do you quantify ideas like strategy diversity, comeback potential, interactivity/counterplay, skill cap/floor, learning curve, etc?
"|data scientist play competit video game ( e.g . moba , autochess , hearthston ) , would model problem game balanc ? most stat websit ( hsreplay.net , op.gg , etc ) focu winrat . how quantifi idea like strategi divers , comeback potenti , interactivity/counterplay , skill cap/floor , learn curv , etc ?
94|DiscussionStrategies for processing .csv files over 1 million rows long (~200 MB .csv files) (self.datascience)|gnuforlyfe|134|143|"At my job, I am juggling keeping our development pace going for the project I'm assigned to while making improvements to our workflow.
I figured out that you can dump a .csv file of a waveform from an oscilloscope, and it is over a million rows. Python is too slow, because I only have access to a dual core 4 GB machine (I am thinking about writing a persuasive letter about getting a cheap 16 GB ram machine with secure, local-only remote access for the entire engineering team, probably either a quad core Intel or Ryzen 3600) so I was wondering what would be best:
*Learn some R lang basics? C++ was the first thing that came to mind because I figured I could just declare 300-400 MB of memory, placing the whole .csv file in 200 and the rest of the program in 100-200? This is the second link that comes up for me when I google ""C++ .csv"". Admittedly, he has a point. I am about using the right tool for a job.
*Learn Postgres? I like the idea of having an excuse to put a database on my resume and then interfacing it with my tried-and-true Python or C++. 
*Go with my first instinct and do it in C++ anyways? I already use python at work and I'm wondering if a tool featuring a C++ parser as the back-end and something like pysimplegui as the front end could be a game-changer at my job.
"|At job , I juggl keep develop pace go project I 'm assign make improv workflow . I figur dump .csv file waveform oscilloscop , million row . python slow , I access dual core 4 GB machin ( I think write persuas letter get cheap 16 GB ram machin secur , local-onli remot access entir engin team , probabl either quad core intel ryzen 3600 ) I wonder would best : *learn R lang basic ? c++ first thing came mind I figur I could declar 300-400 MB memori , place whole .csv file 200 rest program 100-200 ? thi second link come I googl `` c++ .csv '' . admittedli , point . I use right tool job . *learn postgr ? I like idea excus put databas resum interfac tried-and-tru python c++ . *go first instinct c++ anyway ? I alreadi use python work I 'm wonder tool featur c++ parser back-end someth like pysimplegui front end could game-chang job .
95|DiscussionIs it possible to predict a specific date for a customer's next transaction (with some margin of error) ? (self.datascience)|commoner9x|13|6|"I have a dataset of bill payment transactions of our customers with a period of over 1 year and some features like paid amount, transaction date, bill type (power, internet, etc.). At first, I was able to build a classification model from this data to classify whether a customer has a bill payment transaction in the next  7 days (*), but now my boss wants to go a step further: Could you predict a specific date per customer with a reliable margin of error? (**) I'm not sure how one would reformulate and approach this 'new' problem, and how one would backtest/validate the model (what would be the metrics, etc.). Any pointers or ideas would be appreciated.
Edit: I did do some feature engineering in order to fit a gradient boosting into the data for (*) and came up with some aggregated features (per customer) including:
- recency 
- frequency
- customer age (time from first transaction to the end of the studied period)
- statistics of the bill amount (mean, median, kurtosis, min, max, etc.)
- statistics of the day difference between bill payments
- Mode of bill types
- Counts of each bill type, normalised
One thing that confuses me a bit: There are some customers with zero day differences, meaning they paid 2 or more bills in 1 day. I don't know if it will affect the model for (*), and potentially (**). Should those cases be counted as 1 'compound' bill payment?
"|I dataset bill payment transact custom period 1 year featur like paid amount , transact date , bill type ( power , internet , etc. ) . At first , I abl build classif model data classifi whether custom bill payment transact next 7 day ( * ) , boss want go step : could predict specif date per custom reliabl margin error ? ( ** ) I 'm sure one would reformul approach 'new ' problem , one would backtest/valid model ( would metric , etc. ) . ani pointer idea would appreci . edit : I featur engin order fit gradient boost data ( * ) came aggreg featur ( per custom ) includ : - recenc - frequenc - custom age ( time first transact end studi period ) - statist bill amount ( mean , median , kurtosi , min , max , etc . ) - statist day differ bill payment - mode bill type - count bill type , normalis one thing confus bit : there custom zero day differ , mean paid 2 bill 1 day . I n't know affect model ( * ) , potenti ( ** ) . should case count 1 'compound ' bill payment ?
96|ToolingLooking for a graph algorithm (with possible implementation) for social network (self.datascience)|booblaboobloo|6|0|"I'm looking for a graph algorithm with a ""know each other"" functionality. A general input will be total number of people (50-100) and a closeness rating of 1 to 4 associated. So for example, person A knows person B and their closeness rating is 1 (meaning they are unfamiliar to each other). Person A knows C (with a closeness rating of 4 - familiar) and B knows C (with a closeness rating of 4 - familiar). Therefore, A and B are unfamiliar, but C is their mutual friend.
"|I 'm look graph algorithm `` know '' function . A gener input total number peopl ( 50-100 ) close rate 1 4 associ . So exampl , person A know person B close rate 1 ( mean unfamiliar ) . person A know C ( close rate 4 - familiar ) B know C ( close rate 4 - familiar ) . therefor , A B unfamiliar , C mutual friend .
97|DiscussionSeeking Advice: Building a PC For Data Science Work (self.datascience)|RaffikiDaBaboon|20|16|"I'm curious if anyone here has any experience building a PC for work? I've been reading online and some say to have a lot of PCIe lanes while others say it's not important. Same thing regarding dual GPUs, getting a threadripper CPU, and more.
I primarily do cluster analysis, random forests, and regression, but I want to expand my skills in deep learning. I have been working on an RNN for the past 6 months and plan on trying my hand at computer vision. I'm still just learning and working with relatively small datasets, so I don't need a crazy powerful machine.
"|I 'm curiou anyon experi build PC work ? I 've read onlin say lot pcie lane other say 's import . same thing regard dual gpu , get threadripp cpu , . I primarili cluster analysi , random forest , regress , I want expand skill deep learn . I work rnn past 6 month plan tri hand comput vision . I 'm still learn work rel small dataset , I n't need crazi power machin .
98|Does anyone else not like R until they actually use it? (self.datascience)|o_fly_on|46|6|"I have always been in this ambivalence phase with R software: I like what it can do, but I hate R. 
Is it just me?
"|I alway ambival phase R softwar : I like , I hate R. Is ?
99|DiscussionBest Online Accredited Course You've Taken? (self.datascience)|manoflogos|2|0|"I have $8k of company cash every year to spend on accredited courses (aka no coursera/Edx).
What are some good courses you've taken?
"|I $ 8k compani cash everi year spend accredit cours ( aka coursera/edx ) . what good cours 've taken ?
100|CareerAnyone working on Sports Analytics? (self.datascience)|peterlaanguila8|74|267|"I have interested in sports analytics since a few years ago, but now I want to start learning it. That is why I ask you for advice on how to start with sports analytics (readings, courses, public datasets) and any career advice you can provide. Also, for those who are working on it, could you please tell me how did you start on this and what are the tasks you developed in a daily basis regarding SA.
"|I interest sport analyt sinc year ago , I want start learn . that I ask advic start sport analyt ( read , cours , public dataset ) career advic provid . also , work , could pleas tell start task develop daili basi regard SA .
101|Job SearchAny ideas how I could find freelancing data science clients outside freelancing platforms? (self.datascience)|AILaunchpad|29|36|"Really don't want to be bound to freelancing platforms such as Upwork/Freelancer.com but still want to find project opportunities in data science, any ideas how?
"|realli n't want bound freelanc platform upwork/freelancer.com still want find project opportun data scienc , idea ?
102|DiscussionWhat is up with this subreddit. A plea for help (self.datascience)|Ctown_struggles00|131|487|"Why are 99% of the posts here about jobs or up-skilling? Please stop
I want something like ycombinator where the latest developments in technology and research are posted. Library updates, hot takes. Where there are discussions about statistics, machine learning, etc. 
I post insights here but I can't do it alone. 
I've reported nearly every post on the front page for: not being in the sticky thread, treating /r/datascience as a homework helper or crowd-sourced google. 
This sub is just overrun by college students.
"|whi 99 % post job up-skil ? pleas stop I want someth like ycombin latest develop technolog research post . librari updat , hot take . where discuss statist , machin learn , etc . I post insight I ca n't alon . I 've report nearli everi post front page : sticki thread , treat /r/datasci homework helper crowd-sourc googl . thi sub overrun colleg student .
103|"DiscussionWeekly Entering & Transitioning Thread | 24 May 2020 - 31 May 2020 (self.datascience)"|datascience-bot|173|9|"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

Learning resources (e.g. books, tutorials, videos)
Traditional education (e.g. schools, degrees, electives)
Alternative education (e.g. online courses, bootcamps)
Job search questions (e.g. resumes, applying, career prospects)
Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the FAQ and [Resources](Resources) pages on our wiki. You can also search for answers in past weekly threads.
"|welcom week 's enter & transit thread ! thi thread question get start , studi , transit data scienc field . topic includ : learn resourc ( e.g . book , tutori , video ) tradit educ ( e.g . school , degre , elect ) altern educ ( e.g . onlin cours , bootcamp ) job search question ( e.g . resum , appli , career prospect ) elementari question ( e.g . start , next ) while wait answer commun , check faq [ resourc ] ( resourc ) page wiki . you also search answer past weekli thread .
104|ProjectsHow to determine the one optimal decision threshold across multiple predictive models (self.datascience)|J4806|2|4|"I am currently wanting to construct predictive models to identify patients who may have a misdiagnosis of a certain disease. However, the issue is that I have multiple databases and I do not want to combine the data into one set, so I need to create predictive models for each database. On top of that, I wanted to use different model approaches and use the most accurate model.  
I'm currently facing the problem of determining a way to identify the optimal decision threshold to categorize the results of the predictive model as having been misdiagnosed (p=1) or not having been misdiagnosed (p=0). I've read about how we can use Youden's Index to determine the optimal cutoff for a model, but since I'll have multiple models for each of the database, would it make sense to use the SAME cuttoff across all the models and databases or have one for each database (but keep it consistent for each model within the database)? I'm a bit lost on what the best approach is. I haven't been able to find papers that provide detail on how they determine optimal decision thresholds when they have multiple models
P.S. I've read about how you can use the cost of each result (i.e., TP, TN, FP, FN) to determine the threshold, but these values are unknown for my disease of interest. 
Sorry about the long post, and thank you for your help in advance!
"|I current want construct predict model identifi patient may misdiagnosi certain diseas . howev , issu I multipl databas I want combin data one set , I need creat predict model databas . On top , I want use differ model approach use accur model . I 'm current face problem determin way identifi optim decis threshold categor result predict model misdiagnos ( p=1 ) misdiagnos ( p=0 ) . I 've read use youden 's index determin optim cutoff model , sinc I 'll multipl model databas , would make sens use same cuttoff across model databas one databas ( keep consist model within databas ) ? I 'm bit lost best approach . I n't abl find paper provid detail determin optim decis threshold multipl model p. . I 've read use cost result ( i.e. , TP , TN , FP , FN ) determin threshold , valu unknown diseas interest . sorri long post , thank help advanc !
105|DiscussionIs anyone here into marketing analytics? How did you get into it? What are the skills needed? (self.datascience)|Kpopaddiction|51|124|"Edit: Thanks to the person who gave this gold but I would much rather prefer that you donate the amount to a cause/charity you support. Thanks!
Edit 2: Thanks to everyone who answered! All the responses were very insightful.
"|edit : thank person gave gold I would much rather prefer donat amount cause/char support . thank ! edit 2 : thank everyon answer ! all respons insight .
106|DiscussionData Scientists who aren't doing ML: what kind of statistical work do you do? (self.datascience)|___24601|149|320|"I'm curious to hear about data science in a context that's outside of machine learning or predictive algorithms since they are not as talked about. I've heard time-series is pretty popular in finance companies (unsurprisingly) and survival analysis in some insurance companies. I'd love to hear more about how different types of statistics are being used in data science these days!
"|I 'm curiou hear data scienc context 's outsid machin learn predict algorithm sinc talk . I 've heard time-seri pretti popular financ compani ( unsurprisingli ) surviv analysi insur compani . I 'd love hear differ type statist use data scienc day !
107|EducationPlackett-Luce Latent Variable Modeling issues (self.datascience)|gremlin0x|2|2|"So I'm wondering if anyone else has had this issue before. I'm using a Plackett-Luce Latent Variable model to determine rankings based on sets of ranked data. In my dataset, the problem is occasionally the typical top 5 ranked elements (""winners"") could drop to near bottom as some anomaly. In the new updated rankings, the low ranked elements that ""beat"" the winners  immediately skyrocket to the top, even though the drops are clearly anomalies. Does anyone know of strategies to counteract this? Besides just arbitrarily picking this anomalies and excluding them from the rankings, I'm not sure if there's some form of ""smoothing"" I can do to not rapidly adjust the rankings for each set. It seems like just a single anomaly has a massive effect on the rankings, when it probably shouldn't.
"|So I 'm wonder anyon els issu . I 'm use plackett-luc latent variabl model determin rank base set rank data . In dataset , problem occasion typic top 5 rank element ( `` winner '' ) could drop near bottom anomali . In new updat rank , low rank element `` beat '' winner immedi skyrocket top , even though drop clearli anomali . doe anyon know strategi counteract ? besid arbitrarili pick anomali exclud rank , I 'm sure 's form `` smooth '' I rapidli adjust rank set . It seem like singl anomali massiv effect rank , probabl n't .
108|DiscussionIs it worth investing time learning data science if I only want to freelance part-time? (self.datascience)|RowHowlx|9|0|"I'm not looking to pursue a career in it, at least not for the time being. Yet, as I have time to spare during this lockdown and have a great interest in mathematics, I thought I might as well try to learn it.
"|I 'm look pursu career , least time . yet , I time spare lockdown great interest mathemat , I thought I might well tri learn .
109|DiscussionPlease excuse the cliched, Imposter Syndrome post. I still get anxiety when performing basic arithmetic although I can comprehend and explain complex concepts, e.g how a NN works. I feel like there is such a big gap in my math background. Am I alone? (self.datascience)|elisimicr|55|133|"I have been practicing with a mental math app however, I still feel anxious dealing with basic operations like multiplying and subtraction. I think I have gotten my self into a negative self fulfilling prophecy. 
Does any one have any suggestions how I can overcome this incompetence/insecurity?
I’m concerned when I get into industry everyone will see me as an outlier.
"|I practic mental math app howev , I still feel anxiou deal basic oper like multipli subtract . I think I gotten self neg self fulfil propheci . doe one suggest I overcom incompetence/insecur ? I ’ concern I get industri everyon see outlier .
110|Which experiment tracking tools do you recommend? (self.datascience)|yet41|4|1|"I’m looking for a tool to keep track of experiments and I’m wondering if anyone has good experience with any tools out there? Ideally I’m looking something that

uses an api so that I can just log parameters or metrics during my experimental runs
has a decent UI where I can manually add parameters and add notes on experiments
provides some simple comparisons between experiments.

"|I ’ look tool keep track experi I ’ wonder anyon good experi tool ? ideal I ’ look someth use api I log paramet metric experiment run decent UI I manual add paramet add note experi provid simpl comparison experi .
111|EducationSuccessful people that studied DS, and now are in leadership (self.datascience)|runnersgo|10|8|"I saw a lot of folks that are in top management or leading financial institutions (such as banks) having MBAs, ACCA, and such, and I've always wondered if you've seen top management or successful folks having degrees or postgrads in DS?
I think it will great to see those who have studied the field putting the field into practice, especially in leadership!
"|I saw lot folk top manag lead financi institut ( bank ) mba , acca , , I 've alway wonder 've seen top manag success folk degre postgrad DS ? I think great see studi field put field practic , especi leadership !
112|DiscussionTips for presenting a personal project via video conferencing (self.datascience)|hendrix616|12|2|"Wondering if anyone who’s had to remotely present a personal project as part of a technical interview would be willing to share:
1. technologies used for presentation
2. general outline of presentation (slides first, then live demo?)
3. general tips & tricks
The specific video conferencing service is irrelevant. You’re obviously going to be sharing your screen.
EDIT: the interviewers are data scientists themselves and will presumably be fairly familiar with most technical concepts in my project.
"|wonder anyon ’ remot present person project part technic interview would will share : 1. technolog use present 2. gener outlin present ( slide first , live demo ? ) 3. gener tip & trick the specif video conferenc servic irrelev . you ’ obvious go share screen . edit : interview data scientist presum fairli familiar technic concept project .
113|ProjectsData Science in a Restaurant? (self.datascience)|pmp1321|50|284|"Hi everyone, 
I work as a cook at a seafood restaurant and feel like this gives me a unique opportunity to collect some data on how much food we cook/waste a day. I would like to complete a project that predicts how much food we will sell at certain times on different days of the week, is this doable? The restaurant throws out a lot of each night, and I feel like completing a project like this could help solve this problem by predicting how much food needs to be cooked within the last hour of being open and it would also look great on a resume. Do you all have any tips on data collection or models to use? Thanks!
"|Hi everyon , I work cook seafood restaur feel like give uniqu opportun collect data much food cook/wast day . I would like complet project predict much food sell certain time differ day week , doabl ? the restaur throw lot night , I feel like complet project like could help solv problem predict much food need cook within last hour open would also look great resum . Do tip data collect model use ? thank !
114|Deploying machine learning models at scale (self.datascience)|ClassicRelation|14|21|"I have experience with deploying API end points for internal apps that get maybe a hundred or so requests a day.
How does it differ from a large applications with for example hundreds of thousands a request a day, what do I need to consider?
"|I experi deploy api end point intern app get mayb hundr request day . how differ larg applic exampl hundr thousand request day , I need consid ?
115|CareerHow important is title? (self.datascience)|TryWforWumbo|14|8|"Would you consider it a ""step down"" to go from Data Scientist to Senior Analyst/Product Analyst?
"|would consid `` step '' go data scientist senior analyst/product analyst ?
116|DiscussionMaking exploratory Jupyter notebooks more production friendly (self.datascience)|derivablefunc|16|8|"Hello,
I've been hearing polarising opinions on using using Jupyter notebooks in production. My read is that people generally agree on notebooks being useful for exploratory analysis, but the path from there to production seems very vague and very different for different workflows.
Here is what I've found quite useful for my team, made of data analysts, data scientists and me as production engineer. We start from notebooks and gradually end up with code in .py files. It usually involves a hybrid setup of Jupyter web UI and VsCode connected remotely to SageMaker machine, opening the same dir notebooks are in.
There is not quantitative data to back it up, but I feel it didn't decrease the iteration speed and it definitely avoids a lot of ""translation"" from what they write into production code.
What are your thoughts on this?
Do you do something similar?
Is your data setup so complex that it's almost impossible to move from notebook to the production code?
How do you iterate on products where the initial exploration is needed?
How do you make sure there is no loss in the ""translation process""?
Lots of questions, I know :).
"|hello , I 've hear polaris opinion use use jupyt notebook product . My read peopl gener agre notebook use exploratori analysi , path product seem vagu differ differ workflow . here I 've found quit use team , made data analyst , data scientist product engin . We start notebook gradual end code .pi file . It usual involv hybrid setup jupyt web UI vscode connect remot sagemak machin , open dir notebook . there quantit data back , I feel n't decreas iter speed definit avoid lot `` translat '' write product code . what thought ? Do someth similar ? Is data setup complex 's almost imposs move notebook product code ? how iter product initi explor need ? how make sure loss `` translat process '' ? lot question , I know : ) .
117|DiscussionWhat are some bad coding practice you've noticed among Data Scientists? (self.datascience)|shlushfundbaby|205|270|empty|empti
118|DiscussionAlternatives to bag of words processing for finding fake news? (self.datascience)|DrShlomo|7|5|"I'm wondering how word processing algorithms can differentiate between fake news and satirical fake news. Imagine that someone on a website is quoting fake news to ridicule it or to debunk it, a BOW algorithm would flag their content as fake news. What representations could you add into this kind of algorithm to prevent this?
"|I 'm wonder word process algorithm differenti fake news satir fake news . imagin someon websit quot fake news ridicul debunk , bow algorithm would flag content fake news . what represent could add kind algorithm prevent ?
119|DiscussionKeeping statistical knowledge fresh? (self.datascience)|BlackJack5027|29|26|"How do you keep your statistical knowledge fresh and not get rusty?
I haven't come across many jobs in which you need to explain why a model does what it does, either because they're happy when it works or they glaze over the moment you mention anything remotely technical. But you're expected to know it all in an interview if you change jobs.
"|how keep statist knowledg fresh get rusti ? I n't come across mani job need explain model , either 're happi work glaze moment mention anyth remot technic . but 're expect know interview chang job .
